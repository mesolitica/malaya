{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = 'mesolitica-tpu.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "client = storage.Client()\n",
    "bucket = client.bucket('mesolitica-tpu-general')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob = bucket.get_blob('pegasus-data-v2/tfrecord/pegasus-splitted-parliament00.txt.tfrecord')\n",
    "blob.download_to_filename('pegasus-splitted-parliament00.txt.tfrecord')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _decode_record(record, name_to_features):\n",
    "    \"\"\"Decodes a record to a TensorFlow example.\"\"\"\n",
    "    example = tf.parse_single_example(record, name_to_features)\n",
    "\n",
    "    # tf.Example only supports tf.int64, but the TPU only supports tf.int32.\n",
    "    # So cast all int64 to int32.\n",
    "    for name in list(example.keys()):\n",
    "        t = example[name]\n",
    "        if t.dtype == tf.int64:\n",
    "            t = tf.to_int32(t)\n",
    "        example[name] = t\n",
    "\n",
    "    return example\n",
    "\n",
    "def input_fn_builder(\n",
    "    input_files,\n",
    "    max_seq_length_encoder,\n",
    "    max_seq_length_decoder,\n",
    "    max_predictions_per_seq,\n",
    "    is_training,\n",
    "    num_cpu_threads = 4,\n",
    "):\n",
    "    def input_fn(params):\n",
    "        batch_size = params['batch_size']\n",
    "\n",
    "        name_to_features = {\n",
    "            'input_ids': tf.FixedLenFeature([max_seq_length_encoder], tf.int64),\n",
    "            'target_ids': tf.FixedLenFeature(\n",
    "                [max_seq_length_decoder], tf.int64\n",
    "            ),\n",
    "            'masked_lm_positions': tf.FixedLenFeature(\n",
    "                [max_predictions_per_seq], tf.int64\n",
    "            ),\n",
    "            'masked_lm_ids': tf.FixedLenFeature(\n",
    "                [max_predictions_per_seq], tf.int64\n",
    "            ),\n",
    "            'masked_lm_weights': tf.FixedLenFeature(\n",
    "                [max_predictions_per_seq], tf.float32\n",
    "            ),\n",
    "        }\n",
    "        if is_training:\n",
    "            d = tf.data.Dataset.from_tensor_slices(tf.constant(input_files))\n",
    "            d = d.repeat()\n",
    "            d = d.shuffle(buffer_size = len(input_files))\n",
    "            cycle_length = min(num_cpu_threads, len(input_files))\n",
    "            d = d.apply(\n",
    "                tf.contrib.data.parallel_interleave(\n",
    "                    tf.data.TFRecordDataset,\n",
    "                    sloppy = is_training,\n",
    "                    cycle_length = cycle_length,\n",
    "                )\n",
    "            )\n",
    "            d = d.shuffle(buffer_size = 100)\n",
    "        else:\n",
    "            d = tf.data.TFRecordDataset(input_files)\n",
    "            d = d.repeat()\n",
    "        d = d.apply(\n",
    "            tf.contrib.data.map_and_batch(\n",
    "                lambda record: _decode_record(record, name_to_features),\n",
    "                batch_size = batch_size,\n",
    "                num_parallel_batches = num_cpu_threads,\n",
    "                drop_remainder = True,\n",
    "            )\n",
    "        )\n",
    "        return d\n",
    "\n",
    "    return input_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_fn = input_fn_builder(['pegasus-splitted-parliament00.txt.tfrecord'], 512, 256, 0, True)\n",
    "dataset = input_fn({'batch_size': 1})\n",
    "dataset = dataset._make_one_shot_iterator().get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = sess.run(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/husein/t5/prepare/tokenization.py:135: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tokenization\n",
    "\n",
    "tokenizer = tokenization.FullTokenizer(\n",
    "    vocab_file='pegasus.wordpiece', do_lower_case=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['JAWAPAN',\n",
       " ':',\n",
       " 'YB',\n",
       " 'DATO',\n",
       " '*',\n",
       " 'SERI',\n",
       " 'DR',\n",
       " '.',\n",
       " 'SHAH',\n",
       " '##IDA',\n",
       " '##N',\n",
       " 'BIN',\n",
       " 'KAS',\n",
       " '##SI',\n",
       " '##M',\n",
       " 'MENTERI',\n",
       " 'DI',\n",
       " 'JABATAN',\n",
       " 'PERDANA',\n",
       " 'MENTERI',\n",
       " 'Tuan',\n",
       " 'Yang',\n",
       " 'di',\n",
       " '-',\n",
       " 'Pertua',\n",
       " ',',\n",
       " 'Bilangan',\n",
       " 'Rumah',\n",
       " 'Kekal',\n",
       " 'Baharu',\n",
       " '(',\n",
       " 'R',\n",
       " '##KB',\n",
       " ')',\n",
       " 'yang',\n",
       " 'dim',\n",
       " '##ohon',\n",
       " 'oleh',\n",
       " 'mangsa',\n",
       " 'banjir',\n",
       " 'di',\n",
       " 'negeri',\n",
       " 'Kelantan',\n",
       " 'ialah',\n",
       " 'sebanyak',\n",
       " '1',\n",
       " ',',\n",
       " '82',\n",
       " '##7',\n",
       " 'unit',\n",
       " '.',\n",
       " 'Dari',\n",
       " 'jumlah',\n",
       " 'tersebut',\n",
       " ',',\n",
       " 'Kerajaan',\n",
       " 'Persekutuan',\n",
       " 'dipertanggungjawabkan',\n",
       " 'untuk',\n",
       " 'membina',\n",
       " '96',\n",
       " '##6',\n",
       " 'unit',\n",
       " '.',\n",
       " 'Sehingga',\n",
       " '18',\n",
       " 'Mei',\n",
       " '2016',\n",
       " ',',\n",
       " 'Kerajaan',\n",
       " 'Persekutuan',\n",
       " 'telah',\n",
       " 'melaksanakan',\n",
       " 'proses',\n",
       " 'penempatan',\n",
       " 'semula',\n",
       " 'mangsa',\n",
       " 'banjir',\n",
       " 'melalui',\n",
       " 'program',\n",
       " 'rumah',\n",
       " 'berkel',\n",
       " '##ompok',\n",
       " '(',\n",
       " 'Integ',\n",
       " '##rated',\n",
       " 'Res',\n",
       " '##et',\n",
       " '##tle',\n",
       " '##ment',\n",
       " 'Programme',\n",
       " ')',\n",
       " 'di',\n",
       " 'sepuluh',\n",
       " '(',\n",
       " '10',\n",
       " ')',\n",
       " 'lokasi',\n",
       " 'yang',\n",
       " 'telah',\n",
       " 'dikenal',\n",
       " 'pasti',\n",
       " '.',\n",
       " '[MASK2]',\n",
       " '.',\n",
       " '[MASK2]',\n",
       " '.',\n",
       " 'Tapak',\n",
       " 'Maju',\n",
       " 'Ter',\n",
       " '##nak',\n",
       " '43',\n",
       " 'Unit',\n",
       " 'R',\n",
       " '##KB',\n",
       " 'iii',\n",
       " '.',\n",
       " 'Kampung',\n",
       " 'Peri',\n",
       " '##al',\n",
       " '40',\n",
       " 'Unit',\n",
       " 'R',\n",
       " '##KB',\n",
       " 'iv',\n",
       " '.',\n",
       " 'Tapak',\n",
       " 'Pusp',\n",
       " '##ak',\n",
       " '##om',\n",
       " '71',\n",
       " 'Unit',\n",
       " 'R',\n",
       " '##KB',\n",
       " 'v',\n",
       " '.',\n",
       " 'Kampung',\n",
       " 'Kem',\n",
       " '##ubu',\n",
       " '76',\n",
       " 'Unit',\n",
       " 'R',\n",
       " '##KB',\n",
       " 'vi',\n",
       " '.',\n",
       " 'Tapak',\n",
       " 'IL',\n",
       " '##P',\n",
       " '36',\n",
       " 'Unit',\n",
       " 'R',\n",
       " '##KB',\n",
       " 'Jumlah',\n",
       " '360',\n",
       " 'Unit',\n",
       " 'R',\n",
       " '##KB',\n",
       " 'Ja',\n",
       " '##iah',\n",
       " '##an',\n",
       " 'Gua',\n",
       " 'Musang',\n",
       " 'Felda',\n",
       " 'Ari',\n",
       " '##ng',\n",
       " '13',\n",
       " 'Unit',\n",
       " 'R',\n",
       " '##KB',\n",
       " 'ii',\n",
       " '.',\n",
       " 'Bertam',\n",
       " 'Baru',\n",
       " '29',\n",
       " 'Unit',\n",
       " 'R',\n",
       " '##KB',\n",
       " 'iii',\n",
       " '.',\n",
       " 'Leb',\n",
       " '##ir',\n",
       " '15',\n",
       " 'Unit',\n",
       " 'R',\n",
       " '##KB',\n",
       " 'iv',\n",
       " '.',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens(r['input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Berikut',\n",
       " 'adalah',\n",
       " 'lokasi',\n",
       " 'penempatan',\n",
       " 'semula',\n",
       " 'mangsa',\n",
       " 'banjir',\n",
       " '2014',\n",
       " 'di',\n",
       " 'Kelantan',\n",
       " ':',\n",
       " '-',\n",
       " 'Ja',\n",
       " '##iah',\n",
       " '##an',\n",
       " 'Kuala',\n",
       " 'Krai',\n",
       " 'Kampung',\n",
       " 'Telek',\n",
       " '##ong',\n",
       " '94',\n",
       " 'Unit',\n",
       " 'R',\n",
       " '##KB',\n",
       " 'ii',\n",
       " '.',\n",
       " 'Sehingga',\n",
       " '18',\n",
       " 'Mei',\n",
       " '2016',\n",
       " ',',\n",
       " 'Kerajaan',\n",
       " 'Persekutuan',\n",
       " 'telah',\n",
       " 'melaksanakan',\n",
       " 'proses',\n",
       " 'penempatan',\n",
       " 'semula',\n",
       " 'mangsa',\n",
       " 'banjir',\n",
       " 'melalui',\n",
       " 'program',\n",
       " 'rumah',\n",
       " 'berkel',\n",
       " '##ompok',\n",
       " '(',\n",
       " 'Integ',\n",
       " '##rated',\n",
       " 'Res',\n",
       " '##et',\n",
       " '##tle',\n",
       " '##ment',\n",
       " 'Programme',\n",
       " ')',\n",
       " 'di',\n",
       " 'sepuluh',\n",
       " '(',\n",
       " '10',\n",
       " ')',\n",
       " 'lokasi',\n",
       " 'yang',\n",
       " 'telah',\n",
       " 'dikenal',\n",
       " 'pasti',\n",
       " '.',\n",
       " 'Sepuluh',\n",
       " '(',\n",
       " '10',\n",
       " ')',\n",
       " 'lokasi',\n",
       " 'tersebut',\n",
       " 'melibatkan',\n",
       " 'enam',\n",
       " '(',\n",
       " '6',\n",
       " ')',\n",
       " 'tapak',\n",
       " 'berkel',\n",
       " '##ompok',\n",
       " 'di',\n",
       " 'Jajahan',\n",
       " 'Kuala',\n",
       " 'Krai',\n",
       " 'dan',\n",
       " 'empat',\n",
       " '(',\n",
       " '4',\n",
       " ')',\n",
       " 'tapak',\n",
       " 'berkel',\n",
       " '##ompok',\n",
       " 'di',\n",
       " 'Jajahan',\n",
       " 'Gua',\n",
       " 'Musang',\n",
       " '.',\n",
       " '[CLS]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]',\n",
       " '[PAD]']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens(r['target_ids'][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
