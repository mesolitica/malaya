{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
    "\n",
    "from tensor2tensor.data_generators import problem\n",
    "from tensor2tensor.data_generators import text_problems\n",
    "from tensor2tensor.data_generators import translate\n",
    "from tensor2tensor.utils import registry\n",
    "from tensor2tensor import problems\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger()\n",
    "tf.logging.set_verbosity(tf.logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import youtokentome as yttm\n",
    "\n",
    "bpe = yttm.BPE(model='truecase.yttm')\n",
    "\n",
    "class Encoder:\n",
    "    def __init__(self, bpe):\n",
    "        self.bpe = bpe\n",
    "        self.vocab_size = len(self.bpe.vocab())\n",
    "    \n",
    "    def encode(self, s):\n",
    "        s = self.bpe.encode(s, output_type=yttm.OutputType.ID)\n",
    "        s = [i + [1] for i in s]\n",
    "        return s\n",
    "    \n",
    "    def decode(self, ids, strip_extraneous=False):\n",
    "        ids = [[k for k in i if k > 1] for i in ids]\n",
    "        return self.bpe.decode(list(ids))\n",
    "    \n",
    "encoder = Encoder(bpe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@registry.register_problem\n",
    "class TrueCase(text_problems.Text2TextProblem):\n",
    "    @property\n",
    "    def approx_vocab_size(self):\n",
    "        return 32000\n",
    "\n",
    "    @property\n",
    "    def is_generate_per_split(self):\n",
    "        return False\n",
    "\n",
    "    def feature_encoders(self, data_dir):\n",
    "        encoder = Encoder(bpe)\n",
    "        return {'inputs': encoder, 'targets': encoder}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = os.path.expanduser('t2t-true-case/data')\n",
    "TMP_DIR = os.path.expanduser('t2t-true-case/tmp')\n",
    "TRAIN_DIR = os.path.expanduser('t2t-true-case/train-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROBLEM = 'true_case'\n",
    "t2t_problem = problems.problem(PROBLEM)\n",
    "\n",
    "train_steps = 500000\n",
    "eval_steps = 10\n",
    "batch_size = 4096 * 2\n",
    "save_checkpoints_steps = 25000\n",
    "ALPHA = 0.1\n",
    "schedule = 'continuous_train_and_eval'\n",
    "MODEL = 'transformer'\n",
    "HPARAMS = 'transformer_base'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'t2t-true-case/train-base/model.ckpt-350000'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "ckpt_path = tf.train.latest_checkpoint(TRAIN_DIR)\n",
    "ckpt_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/husein/.local/lib/python3.6/site-packages/tensorflow_gan/python/estimator/tpu_gan_estimator.py:42: The name tf.estimator.tpu.TPUEstimator is deprecated. Please use tf.compat.v1.estimator.tpu.TPUEstimator instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/husein/.local/lib/python3.6/site-packages/tensorflow_gan/python/estimator/tpu_gan_estimator.py:42: The name tf.estimator.tpu.TPUEstimator is deprecated. Please use tf.compat.v1.estimator.tpu.TPUEstimator instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tensor2tensor import models\n",
    "from tensor2tensor import problems\n",
    "from tensor2tensor.layers import common_layers\n",
    "from tensor2tensor.utils import trainer_lib\n",
    "from tensor2tensor.utils import t2t_model\n",
    "from tensor2tensor.utils import registry\n",
    "from tensor2tensor.utils import metrics\n",
    "from tensor2tensor.data_generators import problem\n",
    "from tensor2tensor.data_generators import text_problems\n",
    "from tensor2tensor.data_generators import translate\n",
    "from tensor2tensor.utils import registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/husein/.local/lib/python3.6/site-packages/tensorflow_core/python/util/deprecation.py:507: calling count_nonzero (from tensorflow.python.ops.math_ops) with axis is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "reduction_indices is deprecated, use axis instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/husein/.local/lib/python3.6/site-packages/tensorflow_core/python/util/deprecation.py:507: calling count_nonzero (from tensorflow.python.ops.math_ops) with axis is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "reduction_indices is deprecated, use axis instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'infer'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'infer'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function framework at 0x7f568139e598> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: LIVE_VARS_IN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function framework at 0x7f568139e598> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: LIVE_VARS_IN\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <function framework at 0x7f568139e598> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: LIVE_VARS_IN\n",
      "WARNING:tensorflow:From /home/husein/.local/lib/python3.6/site-packages/tensor2tensor-1.15.7-py3.6.egg/tensor2tensor/utils/t2t_model.py:2253: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/husein/.local/lib/python3.6/site-packages/tensor2tensor-1.15.7-py3.6.egg/tensor2tensor/utils/t2t_model.py:2253: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/husein/.local/lib/python3.6/site-packages/tensor2tensor-1.15.7-py3.6.egg/tensor2tensor/utils/t2t_model.py:1374: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/husein/.local/lib/python3.6/site-packages/tensor2tensor-1.15.7-py3.6.egg/tensor2tensor/utils/t2t_model.py:1374: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_32000_512.bottom\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_32000_512.bottom\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/husein/.local/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/husein/.local/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_32000_512.targets_bottom\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_32000_512.targets_bottom\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Building model body\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Building model body\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/husein/.local/lib/python3.6/site-packages/tensor2tensor-1.15.7-py3.6.egg/tensor2tensor/models/transformer.py:95: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/husein/.local/lib/python3.6/site-packages/tensor2tensor-1.15.7-py3.6.egg/tensor2tensor/models/transformer.py:95: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function attention_bias_to_padding at 0x7f567fb5f7b8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function attention_bias_to_padding at 0x7f567fb5f7b8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <function attention_bias_to_padding at 0x7f567fb5f7b8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: \n",
      "WARNING:tensorflow:From /home/husein/.local/lib/python3.6/site-packages/tensor2tensor-1.15.7-py3.6.egg/tensor2tensor/utils/expert_utils.py:621: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/husein/.local/lib/python3.6/site-packages/tensor2tensor-1.15.7-py3.6.egg/tensor2tensor/utils/expert_utils.py:621: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function layers at 0x7f568001e2f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: If not matching a CFG node, must be a block statement: <gast.gast.ImportFrom object at 0x7f56601a7160>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function layers at 0x7f568001e2f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: If not matching a CFG node, must be a block statement: <gast.gast.ImportFrom object at 0x7f56601a7160>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <function layers at 0x7f568001e2f0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: If not matching a CFG node, must be a block statement: <gast.gast.ImportFrom object at 0x7f56601a7160>\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_32000_512.top\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Transforming body output with symbol_modality_32000_512.top\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/husein/.local/lib/python3.6/site-packages/tensor2tensor-1.15.7-py3.6.egg/tensor2tensor/models/transformer.py:1258: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/husein/.local/lib/python3.6/site-packages/tensor2tensor-1.15.7-py3.6.egg/tensor2tensor/models/transformer.py:1258: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_32000_512.bottom\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_32000_512.bottom\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_32000_512.targets_bottom\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_32000_512.targets_bottom\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Building model body\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Building model body\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Transforming body output with symbol_modality_32000_512.top\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Transforming body output with symbol_modality_32000_512.top\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from t2t-true-case/train-base/model.ckpt-350000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from t2t-true-case/train-base/model.ckpt-350000\n"
     ]
    }
   ],
   "source": [
    "class Model:\n",
    "    def __init__(self, HPARAMS = \"transformer_base\", DATA_DIR = 't2t/data'):\n",
    "        \n",
    "        self.X = tf.placeholder(tf.int32, [None, None])\n",
    "        self.Y = tf.placeholder(tf.int32, [None, None])\n",
    "        \n",
    "        self.X_seq_len = tf.count_nonzero(self.X, 1, dtype=tf.int32)\n",
    "        maxlen_decode = tf.reduce_max(self.X_seq_len)\n",
    "        maxlen_decode = 50 + tf.reduce_max(self.X_seq_len)\n",
    "        #self.maxlen_decode = tf.placeholder(tf.int32, None)\n",
    "        \n",
    "        x = tf.expand_dims(tf.expand_dims(self.X, -1), -1)\n",
    "        y = tf.expand_dims(tf.expand_dims(self.Y, -1), -1)\n",
    "        \n",
    "        features = {\n",
    "            \"inputs\": x,\n",
    "            \"targets\": y,\n",
    "            \"target_space_id\": tf.constant(1, dtype=tf.int32),\n",
    "        }\n",
    "        self.features = features\n",
    "        \n",
    "        Modes = tf.estimator.ModeKeys\n",
    "        hparams = trainer_lib.create_hparams(HPARAMS, data_dir=DATA_DIR, problem_name=PROBLEM)\n",
    "        hparams.max_length = 512\n",
    "        \n",
    "        translate_model = registry.model('transformer')(hparams, Modes.PREDICT)\n",
    "        self.translate_model = translate_model\n",
    "        logits, _ = translate_model(features)\n",
    "        self.logits = logits\n",
    "        \n",
    "        with tf.variable_scope(tf.get_variable_scope(), reuse=True):\n",
    "            self.fast_result = translate_model._greedy_infer(features, maxlen_decode)[\"outputs\"]\n",
    "            self.beam_result = translate_model._beam_decode_slow(\n",
    "                features, maxlen_decode, beam_size=3, \n",
    "                top_beams=1, alpha=0.5)[\"outputs\"]\n",
    "        \n",
    "        self.fast_result = tf.identity(self.fast_result, name = 'greedy')\n",
    "        self.beam_result = tf.identity(self.beam_result, name = 'beam')\n",
    "        \n",
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "model = Model()\n",
    "var_lists = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)\n",
    "saver = tf.train.Saver(var_list = var_lists)\n",
    "saver.restore(sess, ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "str1 = 'KUALA LUMPUR - MenteRi Di Jabatan PErdaNa MEnTeri, DaTuk Seri Dr Mujahid YUsof Rawa HAri ini MengaKhiri lAwataN kERja lApaN HarI kE JordAn, TUrki dan BosNiA Herzegovina, lAwAtan yaNg BerTUJUAN menGEratkAn LaGi huBungAn Dua haLa DEngAN KEtIGA-tIga NEgaRa berKeNAan.'\n",
    "str2 = 'kuala lumpur - menteri di jabatan perdana menteri, datuk seri dr mujahid yusof rawa hari ini mengakhiri lawatan kerja lapan hari ke jordan, turki dan bosnia herzegovina, lawatan yang bertujuan mengeratkan lagi hubungan dua hala dengan ketiga-tiga negara berkenaan.'\n",
    "str3 = 'KUALA LUMPUR - Menteri di Jabatan Perdana Menteri , Datuk Seri Dr Mujahid Yusof Rawa hari ini mengakhiri lawatan kerja lapan hari ke Jordan , Turki dan Bosnia Herzegovina , lawatan yang bertujuan mengeratkan lagi hubungan dua hala dengan ketiga-tiga negara berkenaan .'\n",
    "str4 = 'Beliau mengambil nama gelaran Alexandre Pato Alex sang Itik sempena nama tempat kelahirannya'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "long = 'bermula tahun depan bakal anggota polis perlu lulus ujian penilaian agama dan moral sebelum diterima bekerja menurut PDRM yang bagi pastikan Setiap anggotanya yang diambil bertugas mempunyai tahap integriti serta moral dan agama yang tinggi kerana anggota polis takkan dinilai masih hujan secara dalam talian dan temuduga bilangan mangsa banjir di Kota Tinggi Johor naik dikit kepada hampir 720 Orang Sabah juga mula dilanda banjir menyaksikan hampir 400 penduduk di Sipitang Beaufort dan Membakut berlindung di pusat pemindahan Kementerian Sumber Manusia bercadang memberikan insentif 500 sebulan kepada pekerja yang ikuti latihan kemahiran tvet ia bertujuan menambah bilangan pekerja berkemahiran di negara ini dan cadangan itu akan dibentangkan kepada kabinet untuk kelulusan Wisma Putra memaklumkan adalah kerana Darat Malaysia maut dalam letusan ku number of Edward Island New Zealand kelmarin belum dapat disahkan setakat ini yang dapat disahkan adalah seorang Malaysia cedera dan kini kritikal dan di rawat di hospital kerajaan penjawat awam kerajaan Perlis bakal terima bantuan khas kewangan 600 seseorang dan Barang akan dibuat Rabu minggu depan beranikah berita hiburan kumpulan Stone mengakui kedudukan antara yang terbawah di pentas Maharaja Lawak Mega 2019 memberi tekanan kepada mereka namun kumpulan itu memaklumkan Astro Gempak mereka lebih tertekan apabila menerima komen tidak membina daripada juri tu dia anggota yg Mamat Sepah Aziz Senario dan Acong dan anda boleh tonton aksi mereka di pentas MLM 2019 siap Jumaat 9.00 malam di Astro Warna'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padding_sequence(seq, maxlen = None, padding = 'post', pad_int = 0):\n",
    "    if not maxlen:\n",
    "        maxlen = max([len(i) for i in seq])\n",
    "    padded_seqs = []\n",
    "    for s in seq:\n",
    "        if padding == 'post':\n",
    "            padded_seqs.append(s + [pad_int] * (maxlen - len(s)))\n",
    "        if padding == 'pre':\n",
    "            padded_seqs.append([pad_int] * (maxlen - len(s)) + s)\n",
    "    return padded_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'kuala lumpur menteri di jabatan perdana menteri datuk seri dr mujahid yusof rawa hari ini mengakhiri lawatan kerja lapan hari ke jordan turki dan bosnia herzegovina lawatan yang bertujuan mengeratkan lagi hubungan dua hala dengan ketiga tiga negara berkenaan'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import random\n",
    "\n",
    "punctuation = '!()&%{}[];:\\'\",./?\\\\<>'\n",
    "\n",
    "def remove_punc(string):\n",
    "    string = re.sub('[^A-Za-z0-9 ]+', ' ', string)\n",
    "    string = re.sub(r'[ ]+', ' ', string).strip()\n",
    "    return string\n",
    "\n",
    "remove_punc(str3).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bermula tahun depan. bakal anggota polis perlu lulus ujian penilaian agama dan moral sebelum diterima bekerja, menurut PDRM yang bagi pastikan. Setiap anggotanya yang diambil bertugas mempunyai tahap integriti serta moral dan agama yang tinggi kerana anggota polis takkan dinilai masih hujan secara dalam talian dan temuduga bilangan mangsa banjir di Kota Tinggi, Johor naik dikit kepada hampir 720 Orang Sabah juga mula dilanda banjir menyaksikan hampir 400 penduduk di Sipitang, Beaufort dan Membakut berlindung di pusat pemindahan Kementerian Sumber Manusia bercadang memberikan insentif 500 sebulan kepada pekerja yang ikuti latihan kemahiran TVET, ia bertujuan menambah bilangan pekerja berkemahiran di negara ini dan cadangan itu akan dibentangkan kepada kabinet untuk kelulusan Wisma Putra memaklumkan adalah kerana Darat Malaysia maut dalam letusan ku number of Edward Island, New Zealand kelmarin belum dapat disahkan setakat ini. yang dapat disahkan adalah seorang Malaysia cedera dan kini kritikal dan di rawat di hospital kerajaan, penjawat awam kerajaan Perlis bakal terima bantuan khas kewangan 600 seseorang dan Barang akan dibuat Rabu minggu depan. beranikah berita hiburan kumpulan Stone mengakui kedudukan antara yang terbawah di pentas Maharaja Lawak Mega 2019 memberi tekanan kepada mereka, namun kumpulan itu memaklumkan Astro Gempak mereka lebih tertekan apabila menerima komen tidak membina daripada juri tu dia anggota yg Mamat Sepah, Aziz Senario dan Acong dan anda boleh tonton aksi mereka di pentas MLM 2019 siap Jumaat 9.00 malam di Astro Warna.<EOS>'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded = padding_sequence(encoder.encode([long, str1, str2, remove_punc(str3).lower()]))\n",
    "greedy = sess.run(model.fast_result, \n",
    "             feed_dict = {model.X: encoded})\n",
    "encoder.decode(greedy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'transformer-base/model.ckpt'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saver = tf.train.Saver(tf.trainable_variables())\n",
    "saver.save(sess, 'transformer-base/model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Placeholder',\n",
       " 'Placeholder_1',\n",
       " 'transformer/body/target_space_embedding/kernel/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/target_space_embedding/ReadVariableOp',\n",
       " 'transformer/body/encoder/layer_0/self_attention/layer_prepostprocess/layer_norm/layer_norm_scale/Read/ReadVariableOp',\n",
       " 'transformer/body/encoder/layer_0/self_attention/layer_prepostprocess/layer_norm/layer_norm_bias/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/encoder/layer_0/self_attention/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/encoder/layer_0/self_attention/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer/body/encoder/layer_0/self_attention/multihead_attention/q/kernel/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/encoder/layer_0/self_attention/multihead_attention/q/Tensordot/ReadVariableOp',\n",
       " 'transformer/body/encoder/layer_0/self_attention/multihead_attention/k/kernel/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/encoder/layer_0/self_attention/multihead_attention/k/Tensordot/ReadVariableOp',\n",
       " 'transformer/body/encoder/layer_0/self_attention/multihead_attention/v/kernel/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/encoder/layer_0/self_attention/multihead_attention/v/Tensordot/ReadVariableOp',\n",
       " 'transformer/body/encoder/layer_0/self_attention/multihead_attention/output_transform/kernel/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/encoder/layer_0/self_attention/multihead_attention/output_transform/Tensordot/ReadVariableOp',\n",
       " 'transformer/body/encoder/layer_0/ffn/layer_prepostprocess/layer_norm/layer_norm_scale/Read/ReadVariableOp',\n",
       " 'transformer/body/encoder/layer_0/ffn/layer_prepostprocess/layer_norm/layer_norm_bias/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/encoder/layer_0/ffn/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/encoder/layer_0/ffn/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer/body/encoder/layer_0/ffn/conv1/kernel/Read/ReadVariableOp',\n",
       " 'transformer/body/encoder/layer_0/ffn/conv1/bias/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/encoder/layer_0/ffn/conv1/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/encoder/layer_0/ffn/conv1/BiasAdd/ReadVariableOp',\n",
       " 'transformer/body/encoder/layer_0/ffn/conv2/kernel/Read/ReadVariableOp',\n",
       " 'transformer/body/encoder/layer_0/ffn/conv2/bias/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/encoder/layer_0/ffn/conv2/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/encoder/layer_0/ffn/conv2/BiasAdd/ReadVariableOp',\n",
       " 'transformer/body/encoder/layer_1/self_attention/layer_prepostprocess/layer_norm/layer_norm_scale/Read/ReadVariableOp',\n",
       " 'transformer/body/encoder/layer_1/self_attention/layer_prepostprocess/layer_norm/layer_norm_bias/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/encoder/layer_1/self_attention/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/encoder/layer_1/self_attention/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer/body/encoder/layer_1/self_attention/multihead_attention/q/kernel/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/encoder/layer_1/self_attention/multihead_attention/q/Tensordot/ReadVariableOp',\n",
       " 'transformer/body/encoder/layer_1/self_attention/multihead_attention/k/kernel/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/encoder/layer_1/self_attention/multihead_attention/k/Tensordot/ReadVariableOp',\n",
       " 'transformer/body/encoder/layer_1/self_attention/multihead_attention/v/kernel/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/encoder/layer_1/self_attention/multihead_attention/v/Tensordot/ReadVariableOp',\n",
       " 'transformer/body/encoder/layer_1/self_attention/multihead_attention/output_transform/kernel/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/encoder/layer_1/self_attention/multihead_attention/output_transform/Tensordot/ReadVariableOp',\n",
       " 'transformer/body/encoder/layer_1/ffn/layer_prepostprocess/layer_norm/layer_norm_scale/Read/ReadVariableOp',\n",
       " 'transformer/body/encoder/layer_1/ffn/layer_prepostprocess/layer_norm/layer_norm_bias/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/encoder/layer_1/ffn/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/encoder/layer_1/ffn/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer/body/encoder/layer_1/ffn/conv1/kernel/Read/ReadVariableOp',\n",
       " 'transformer/body/encoder/layer_1/ffn/conv1/bias/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/encoder/layer_1/ffn/conv1/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/encoder/layer_1/ffn/conv1/BiasAdd/ReadVariableOp',\n",
       " 'transformer/body/encoder/layer_1/ffn/conv2/kernel/Read/ReadVariableOp',\n",
       " 'transformer/body/encoder/layer_1/ffn/conv2/bias/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/encoder/layer_1/ffn/conv2/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/encoder/layer_1/ffn/conv2/BiasAdd/ReadVariableOp',\n",
       " 'transformer/body/encoder/layer_2/self_attention/layer_prepostprocess/layer_norm/layer_norm_scale/Read/ReadVariableOp',\n",
       " 'transformer/body/encoder/layer_2/self_attention/layer_prepostprocess/layer_norm/layer_norm_bias/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/encoder/layer_2/self_attention/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/encoder/layer_2/self_attention/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer/body/encoder/layer_2/self_attention/multihead_attention/q/kernel/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/encoder/layer_2/self_attention/multihead_attention/q/Tensordot/ReadVariableOp',\n",
       " 'transformer/body/encoder/layer_2/self_attention/multihead_attention/k/kernel/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/encoder/layer_2/self_attention/multihead_attention/k/Tensordot/ReadVariableOp',\n",
       " 'transformer/body/encoder/layer_2/self_attention/multihead_attention/v/kernel/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/encoder/layer_2/self_attention/multihead_attention/v/Tensordot/ReadVariableOp',\n",
       " 'transformer/body/encoder/layer_2/self_attention/multihead_attention/output_transform/kernel/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/encoder/layer_2/self_attention/multihead_attention/output_transform/Tensordot/ReadVariableOp',\n",
       " 'transformer/body/encoder/layer_2/ffn/layer_prepostprocess/layer_norm/layer_norm_scale/Read/ReadVariableOp',\n",
       " 'transformer/body/encoder/layer_2/ffn/layer_prepostprocess/layer_norm/layer_norm_bias/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/encoder/layer_2/ffn/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/encoder/layer_2/ffn/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer/body/encoder/layer_2/ffn/conv1/kernel/Read/ReadVariableOp',\n",
       " 'transformer/body/encoder/layer_2/ffn/conv1/bias/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/encoder/layer_2/ffn/conv1/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/encoder/layer_2/ffn/conv1/BiasAdd/ReadVariableOp',\n",
       " 'transformer/body/encoder/layer_2/ffn/conv2/kernel/Read/ReadVariableOp',\n",
       " 'transformer/body/encoder/layer_2/ffn/conv2/bias/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/encoder/layer_2/ffn/conv2/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/encoder/layer_2/ffn/conv2/BiasAdd/ReadVariableOp',\n",
       " 'transformer/body/encoder/layer_3/self_attention/layer_prepostprocess/layer_norm/layer_norm_scale/Read/ReadVariableOp',\n",
       " 'transformer/body/encoder/layer_3/self_attention/layer_prepostprocess/layer_norm/layer_norm_bias/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/encoder/layer_3/self_attention/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/encoder/layer_3/self_attention/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer/body/encoder/layer_3/self_attention/multihead_attention/q/kernel/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/encoder/layer_3/self_attention/multihead_attention/q/Tensordot/ReadVariableOp',\n",
       " 'transformer/body/encoder/layer_3/self_attention/multihead_attention/k/kernel/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/encoder/layer_3/self_attention/multihead_attention/k/Tensordot/ReadVariableOp',\n",
       " 'transformer/body/encoder/layer_3/self_attention/multihead_attention/v/kernel/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/encoder/layer_3/self_attention/multihead_attention/v/Tensordot/ReadVariableOp',\n",
       " 'transformer/body/encoder/layer_3/self_attention/multihead_attention/output_transform/kernel/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/encoder/layer_3/self_attention/multihead_attention/output_transform/Tensordot/ReadVariableOp',\n",
       " 'transformer/body/encoder/layer_3/ffn/layer_prepostprocess/layer_norm/layer_norm_scale/Read/ReadVariableOp',\n",
       " 'transformer/body/encoder/layer_3/ffn/layer_prepostprocess/layer_norm/layer_norm_bias/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/encoder/layer_3/ffn/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/encoder/layer_3/ffn/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer/body/encoder/layer_3/ffn/conv1/kernel/Read/ReadVariableOp',\n",
       " 'transformer/body/encoder/layer_3/ffn/conv1/bias/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/encoder/layer_3/ffn/conv1/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/encoder/layer_3/ffn/conv1/BiasAdd/ReadVariableOp',\n",
       " 'transformer/body/encoder/layer_3/ffn/conv2/kernel/Read/ReadVariableOp',\n",
       " 'transformer/body/encoder/layer_3/ffn/conv2/bias/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/encoder/layer_3/ffn/conv2/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/encoder/layer_3/ffn/conv2/BiasAdd/ReadVariableOp',\n",
       " 'transformer/body/encoder/layer_4/self_attention/layer_prepostprocess/layer_norm/layer_norm_scale/Read/ReadVariableOp',\n",
       " 'transformer/body/encoder/layer_4/self_attention/layer_prepostprocess/layer_norm/layer_norm_bias/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/encoder/layer_4/self_attention/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/encoder/layer_4/self_attention/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer/body/encoder/layer_4/self_attention/multihead_attention/q/kernel/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/encoder/layer_4/self_attention/multihead_attention/q/Tensordot/ReadVariableOp',\n",
       " 'transformer/body/encoder/layer_4/self_attention/multihead_attention/k/kernel/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/encoder/layer_4/self_attention/multihead_attention/k/Tensordot/ReadVariableOp',\n",
       " 'transformer/body/encoder/layer_4/self_attention/multihead_attention/v/kernel/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/encoder/layer_4/self_attention/multihead_attention/v/Tensordot/ReadVariableOp',\n",
       " 'transformer/body/encoder/layer_4/self_attention/multihead_attention/output_transform/kernel/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/encoder/layer_4/self_attention/multihead_attention/output_transform/Tensordot/ReadVariableOp',\n",
       " 'transformer/body/encoder/layer_4/ffn/layer_prepostprocess/layer_norm/layer_norm_scale/Read/ReadVariableOp',\n",
       " 'transformer/body/encoder/layer_4/ffn/layer_prepostprocess/layer_norm/layer_norm_bias/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/encoder/layer_4/ffn/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/encoder/layer_4/ffn/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer/body/encoder/layer_4/ffn/conv1/kernel/Read/ReadVariableOp',\n",
       " 'transformer/body/encoder/layer_4/ffn/conv1/bias/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/encoder/layer_4/ffn/conv1/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/encoder/layer_4/ffn/conv1/BiasAdd/ReadVariableOp',\n",
       " 'transformer/body/encoder/layer_4/ffn/conv2/kernel/Read/ReadVariableOp',\n",
       " 'transformer/body/encoder/layer_4/ffn/conv2/bias/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/encoder/layer_4/ffn/conv2/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/encoder/layer_4/ffn/conv2/BiasAdd/ReadVariableOp',\n",
       " 'transformer/body/encoder/layer_5/self_attention/layer_prepostprocess/layer_norm/layer_norm_scale/Read/ReadVariableOp',\n",
       " 'transformer/body/encoder/layer_5/self_attention/layer_prepostprocess/layer_norm/layer_norm_bias/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/encoder/layer_5/self_attention/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/encoder/layer_5/self_attention/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer/body/encoder/layer_5/self_attention/multihead_attention/q/kernel/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/encoder/layer_5/self_attention/multihead_attention/q/Tensordot/ReadVariableOp',\n",
       " 'transformer/body/encoder/layer_5/self_attention/multihead_attention/k/kernel/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/encoder/layer_5/self_attention/multihead_attention/k/Tensordot/ReadVariableOp',\n",
       " 'transformer/body/encoder/layer_5/self_attention/multihead_attention/v/kernel/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/encoder/layer_5/self_attention/multihead_attention/v/Tensordot/ReadVariableOp',\n",
       " 'transformer/body/encoder/layer_5/self_attention/multihead_attention/output_transform/kernel/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/encoder/layer_5/self_attention/multihead_attention/output_transform/Tensordot/ReadVariableOp',\n",
       " 'transformer/body/encoder/layer_5/ffn/layer_prepostprocess/layer_norm/layer_norm_scale/Read/ReadVariableOp',\n",
       " 'transformer/body/encoder/layer_5/ffn/layer_prepostprocess/layer_norm/layer_norm_bias/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/encoder/layer_5/ffn/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/encoder/layer_5/ffn/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer/body/encoder/layer_5/ffn/conv1/kernel/Read/ReadVariableOp',\n",
       " 'transformer/body/encoder/layer_5/ffn/conv1/bias/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/encoder/layer_5/ffn/conv1/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/encoder/layer_5/ffn/conv1/BiasAdd/ReadVariableOp',\n",
       " 'transformer/body/encoder/layer_5/ffn/conv2/kernel/Read/ReadVariableOp',\n",
       " 'transformer/body/encoder/layer_5/ffn/conv2/bias/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/encoder/layer_5/ffn/conv2/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/encoder/layer_5/ffn/conv2/BiasAdd/ReadVariableOp',\n",
       " 'transformer/body/encoder/layer_prepostprocess/layer_norm/layer_norm_scale/Read/ReadVariableOp',\n",
       " 'transformer/body/encoder/layer_prepostprocess/layer_norm/layer_norm_bias/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/encoder/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/encoder/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer/body/decoder/layer_0/self_attention/layer_prepostprocess/layer_norm/layer_norm_scale/Read/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_0/self_attention/layer_prepostprocess/layer_norm/layer_norm_bias/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_0/self_attention/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_0/self_attention/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer/body/decoder/layer_0/self_attention/multihead_attention/q/kernel/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_0/self_attention/multihead_attention/q/Tensordot/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_0/self_attention/multihead_attention/k/kernel/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_0/self_attention/multihead_attention/k/Tensordot/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_0/self_attention/multihead_attention/v/kernel/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_0/self_attention/multihead_attention/v/Tensordot/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_0/self_attention/multihead_attention/output_transform/kernel/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_0/self_attention/multihead_attention/output_transform/Tensordot/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_0/encdec_attention/layer_prepostprocess/layer_norm/layer_norm_scale/Read/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_0/encdec_attention/layer_prepostprocess/layer_norm/layer_norm_bias/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_0/encdec_attention/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_0/encdec_attention/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer/body/decoder/layer_0/encdec_attention/multihead_attention/q/kernel/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_0/encdec_attention/multihead_attention/q/Tensordot/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_0/encdec_attention/multihead_attention/k/kernel/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_0/encdec_attention/multihead_attention/k/Tensordot/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_0/encdec_attention/multihead_attention/v/kernel/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_0/encdec_attention/multihead_attention/v/Tensordot/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_0/encdec_attention/multihead_attention/output_transform/kernel/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_0/encdec_attention/multihead_attention/output_transform/Tensordot/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_0/ffn/layer_prepostprocess/layer_norm/layer_norm_scale/Read/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_0/ffn/layer_prepostprocess/layer_norm/layer_norm_bias/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_0_1/ffn/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_0_1/ffn/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer/body/decoder/layer_0/ffn/conv1/kernel/Read/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_0/ffn/conv1/bias/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_0_1/ffn/conv1/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_0_1/ffn/conv1/BiasAdd/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_0/ffn/conv2/kernel/Read/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_0/ffn/conv2/bias/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_0_1/ffn/conv2/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_0_1/ffn/conv2/BiasAdd/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_1/self_attention/layer_prepostprocess/layer_norm/layer_norm_scale/Read/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_1/self_attention/layer_prepostprocess/layer_norm/layer_norm_bias/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_1/self_attention/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_1/self_attention/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer/body/decoder/layer_1/self_attention/multihead_attention/q/kernel/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_1/self_attention/multihead_attention/q/Tensordot/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_1/self_attention/multihead_attention/k/kernel/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_1/self_attention/multihead_attention/k/Tensordot/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_1/self_attention/multihead_attention/v/kernel/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_1/self_attention/multihead_attention/v/Tensordot/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_1/self_attention/multihead_attention/output_transform/kernel/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_1/self_attention/multihead_attention/output_transform/Tensordot/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_1/encdec_attention/layer_prepostprocess/layer_norm/layer_norm_scale/Read/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_1/encdec_attention/layer_prepostprocess/layer_norm/layer_norm_bias/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_1/encdec_attention/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_1/encdec_attention/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer/body/decoder/layer_1/encdec_attention/multihead_attention/q/kernel/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_1/encdec_attention/multihead_attention/q/Tensordot/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_1/encdec_attention/multihead_attention/k/kernel/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_1/encdec_attention/multihead_attention/k/Tensordot/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_1/encdec_attention/multihead_attention/v/kernel/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_1/encdec_attention/multihead_attention/v/Tensordot/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_1/encdec_attention/multihead_attention/output_transform/kernel/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_1/encdec_attention/multihead_attention/output_transform/Tensordot/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_1/ffn/layer_prepostprocess/layer_norm/layer_norm_scale/Read/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_1/ffn/layer_prepostprocess/layer_norm/layer_norm_bias/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_1_1/ffn/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_1_1/ffn/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer/body/decoder/layer_1/ffn/conv1/kernel/Read/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_1/ffn/conv1/bias/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_1_1/ffn/conv1/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_1_1/ffn/conv1/BiasAdd/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_1/ffn/conv2/kernel/Read/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_1/ffn/conv2/bias/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_1_1/ffn/conv2/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_1_1/ffn/conv2/BiasAdd/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_2/self_attention/layer_prepostprocess/layer_norm/layer_norm_scale/Read/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_2/self_attention/layer_prepostprocess/layer_norm/layer_norm_bias/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_2/self_attention/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_2/self_attention/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer/body/decoder/layer_2/self_attention/multihead_attention/q/kernel/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_2/self_attention/multihead_attention/q/Tensordot/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_2/self_attention/multihead_attention/k/kernel/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_2/self_attention/multihead_attention/k/Tensordot/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_2/self_attention/multihead_attention/v/kernel/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_2/self_attention/multihead_attention/v/Tensordot/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_2/self_attention/multihead_attention/output_transform/kernel/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_2/self_attention/multihead_attention/output_transform/Tensordot/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_2/encdec_attention/layer_prepostprocess/layer_norm/layer_norm_scale/Read/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_2/encdec_attention/layer_prepostprocess/layer_norm/layer_norm_bias/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_2/encdec_attention/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_2/encdec_attention/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer/body/decoder/layer_2/encdec_attention/multihead_attention/q/kernel/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_2/encdec_attention/multihead_attention/q/Tensordot/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_2/encdec_attention/multihead_attention/k/kernel/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_2/encdec_attention/multihead_attention/k/Tensordot/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_2/encdec_attention/multihead_attention/v/kernel/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_2/encdec_attention/multihead_attention/v/Tensordot/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_2/encdec_attention/multihead_attention/output_transform/kernel/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_2/encdec_attention/multihead_attention/output_transform/Tensordot/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_2/ffn/layer_prepostprocess/layer_norm/layer_norm_scale/Read/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_2/ffn/layer_prepostprocess/layer_norm/layer_norm_bias/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_2_1/ffn/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_2_1/ffn/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer/body/decoder/layer_2/ffn/conv1/kernel/Read/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_2/ffn/conv1/bias/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_2_1/ffn/conv1/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_2_1/ffn/conv1/BiasAdd/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_2/ffn/conv2/kernel/Read/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_2/ffn/conv2/bias/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_2_1/ffn/conv2/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_2_1/ffn/conv2/BiasAdd/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_3/self_attention/layer_prepostprocess/layer_norm/layer_norm_scale/Read/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_3/self_attention/layer_prepostprocess/layer_norm/layer_norm_bias/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_3/self_attention/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_3/self_attention/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer/body/decoder/layer_3/self_attention/multihead_attention/q/kernel/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_3/self_attention/multihead_attention/q/Tensordot/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_3/self_attention/multihead_attention/k/kernel/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_3/self_attention/multihead_attention/k/Tensordot/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_3/self_attention/multihead_attention/v/kernel/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_3/self_attention/multihead_attention/v/Tensordot/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_3/self_attention/multihead_attention/output_transform/kernel/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_3/self_attention/multihead_attention/output_transform/Tensordot/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_3/encdec_attention/layer_prepostprocess/layer_norm/layer_norm_scale/Read/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_3/encdec_attention/layer_prepostprocess/layer_norm/layer_norm_bias/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_3/encdec_attention/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_3/encdec_attention/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer/body/decoder/layer_3/encdec_attention/multihead_attention/q/kernel/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_3/encdec_attention/multihead_attention/q/Tensordot/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_3/encdec_attention/multihead_attention/k/kernel/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_3/encdec_attention/multihead_attention/k/Tensordot/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_3/encdec_attention/multihead_attention/v/kernel/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_3/encdec_attention/multihead_attention/v/Tensordot/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_3/encdec_attention/multihead_attention/output_transform/kernel/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_3/encdec_attention/multihead_attention/output_transform/Tensordot/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_3/ffn/layer_prepostprocess/layer_norm/layer_norm_scale/Read/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_3/ffn/layer_prepostprocess/layer_norm/layer_norm_bias/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_3_1/ffn/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_3_1/ffn/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer/body/decoder/layer_3/ffn/conv1/kernel/Read/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_3/ffn/conv1/bias/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_3_1/ffn/conv1/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_3_1/ffn/conv1/BiasAdd/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_3/ffn/conv2/kernel/Read/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_3/ffn/conv2/bias/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_3_1/ffn/conv2/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_3_1/ffn/conv2/BiasAdd/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_4/self_attention/layer_prepostprocess/layer_norm/layer_norm_scale/Read/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_4/self_attention/layer_prepostprocess/layer_norm/layer_norm_bias/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_4/self_attention/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_4/self_attention/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer/body/decoder/layer_4/self_attention/multihead_attention/q/kernel/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_4/self_attention/multihead_attention/q/Tensordot/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_4/self_attention/multihead_attention/k/kernel/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_4/self_attention/multihead_attention/k/Tensordot/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_4/self_attention/multihead_attention/v/kernel/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_4/self_attention/multihead_attention/v/Tensordot/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_4/self_attention/multihead_attention/output_transform/kernel/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_4/self_attention/multihead_attention/output_transform/Tensordot/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_4/encdec_attention/layer_prepostprocess/layer_norm/layer_norm_scale/Read/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_4/encdec_attention/layer_prepostprocess/layer_norm/layer_norm_bias/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_4/encdec_attention/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_4/encdec_attention/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer/body/decoder/layer_4/encdec_attention/multihead_attention/q/kernel/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_4/encdec_attention/multihead_attention/q/Tensordot/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_4/encdec_attention/multihead_attention/k/kernel/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_4/encdec_attention/multihead_attention/k/Tensordot/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_4/encdec_attention/multihead_attention/v/kernel/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_4/encdec_attention/multihead_attention/v/Tensordot/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_4/encdec_attention/multihead_attention/output_transform/kernel/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_4/encdec_attention/multihead_attention/output_transform/Tensordot/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_4/ffn/layer_prepostprocess/layer_norm/layer_norm_scale/Read/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_4/ffn/layer_prepostprocess/layer_norm/layer_norm_bias/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_4_1/ffn/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_4_1/ffn/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer/body/decoder/layer_4/ffn/conv1/kernel/Read/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_4/ffn/conv1/bias/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_4_1/ffn/conv1/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_4_1/ffn/conv1/BiasAdd/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_4/ffn/conv2/kernel/Read/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_4/ffn/conv2/bias/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_4_1/ffn/conv2/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_4_1/ffn/conv2/BiasAdd/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_5/self_attention/layer_prepostprocess/layer_norm/layer_norm_scale/Read/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_5/self_attention/layer_prepostprocess/layer_norm/layer_norm_bias/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_5/self_attention/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_5/self_attention/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer/body/decoder/layer_5/self_attention/multihead_attention/q/kernel/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_5/self_attention/multihead_attention/q/Tensordot/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_5/self_attention/multihead_attention/k/kernel/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_5/self_attention/multihead_attention/k/Tensordot/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_5/self_attention/multihead_attention/v/kernel/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_5/self_attention/multihead_attention/v/Tensordot/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_5/self_attention/multihead_attention/output_transform/kernel/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_5/self_attention/multihead_attention/output_transform/Tensordot/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_5/encdec_attention/layer_prepostprocess/layer_norm/layer_norm_scale/Read/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_5/encdec_attention/layer_prepostprocess/layer_norm/layer_norm_bias/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_5/encdec_attention/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_5/encdec_attention/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer/body/decoder/layer_5/encdec_attention/multihead_attention/q/kernel/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_5/encdec_attention/multihead_attention/q/Tensordot/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_5/encdec_attention/multihead_attention/k/kernel/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_5/encdec_attention/multihead_attention/k/Tensordot/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_5/encdec_attention/multihead_attention/v/kernel/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_5/encdec_attention/multihead_attention/v/Tensordot/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_5/encdec_attention/multihead_attention/output_transform/kernel/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_5/encdec_attention/multihead_attention/output_transform/Tensordot/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_5/ffn/layer_prepostprocess/layer_norm/layer_norm_scale/Read/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_5/ffn/layer_prepostprocess/layer_norm/layer_norm_bias/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_5_1/ffn/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_5_1/ffn/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer/body/decoder/layer_5/ffn/conv1/kernel/Read/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_5/ffn/conv1/bias/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_5_1/ffn/conv1/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_5_1/ffn/conv1/BiasAdd/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_5/ffn/conv2/kernel/Read/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_5/ffn/conv2/bias/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_5_1/ffn/conv2/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_5_1/ffn/conv2/BiasAdd/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_prepostprocess/layer_norm/layer_norm_scale/Read/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_prepostprocess/layer_norm/layer_norm_bias/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer_1/body/parallel_0/body/target_space_embedding/ReadVariableOp',\n",
       " 'transformer_1/body/parallel_0/body/encoder/layer_0/self_attention/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer_1/body/parallel_0/body/encoder/layer_0/self_attention/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer_1/body/parallel_0/body/encoder/layer_0/self_attention/multihead_attention/q/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/body/parallel_0/body/encoder/layer_0/self_attention/multihead_attention/k/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/body/parallel_0/body/encoder/layer_0/self_attention/multihead_attention/v/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/body/parallel_0/body/encoder/layer_0/self_attention/multihead_attention/output_transform/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/body/parallel_0/body/encoder/layer_0/ffn/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer_1/body/parallel_0/body/encoder/layer_0/ffn/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer_1/body/parallel_0/body/encoder/layer_0/ffn/conv1/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/body/parallel_0/body/encoder/layer_0/ffn/conv1/BiasAdd/ReadVariableOp',\n",
       " 'transformer_1/body/parallel_0/body/encoder/layer_0/ffn/conv2/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/body/parallel_0/body/encoder/layer_0/ffn/conv2/BiasAdd/ReadVariableOp',\n",
       " 'transformer_1/body/parallel_0/body/encoder/layer_1/self_attention/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer_1/body/parallel_0/body/encoder/layer_1/self_attention/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer_1/body/parallel_0/body/encoder/layer_1/self_attention/multihead_attention/q/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/body/parallel_0/body/encoder/layer_1/self_attention/multihead_attention/k/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/body/parallel_0/body/encoder/layer_1/self_attention/multihead_attention/v/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/body/parallel_0/body/encoder/layer_1/self_attention/multihead_attention/output_transform/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/body/parallel_0/body/encoder/layer_1/ffn/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer_1/body/parallel_0/body/encoder/layer_1/ffn/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer_1/body/parallel_0/body/encoder/layer_1/ffn/conv1/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/body/parallel_0/body/encoder/layer_1/ffn/conv1/BiasAdd/ReadVariableOp',\n",
       " 'transformer_1/body/parallel_0/body/encoder/layer_1/ffn/conv2/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/body/parallel_0/body/encoder/layer_1/ffn/conv2/BiasAdd/ReadVariableOp',\n",
       " 'transformer_1/body/parallel_0/body/encoder/layer_2/self_attention/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer_1/body/parallel_0/body/encoder/layer_2/self_attention/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer_1/body/parallel_0/body/encoder/layer_2/self_attention/multihead_attention/q/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/body/parallel_0/body/encoder/layer_2/self_attention/multihead_attention/k/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/body/parallel_0/body/encoder/layer_2/self_attention/multihead_attention/v/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/body/parallel_0/body/encoder/layer_2/self_attention/multihead_attention/output_transform/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/body/parallel_0/body/encoder/layer_2/ffn/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer_1/body/parallel_0/body/encoder/layer_2/ffn/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer_1/body/parallel_0/body/encoder/layer_2/ffn/conv1/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/body/parallel_0/body/encoder/layer_2/ffn/conv1/BiasAdd/ReadVariableOp',\n",
       " 'transformer_1/body/parallel_0/body/encoder/layer_2/ffn/conv2/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/body/parallel_0/body/encoder/layer_2/ffn/conv2/BiasAdd/ReadVariableOp',\n",
       " 'transformer_1/body/parallel_0/body/encoder/layer_3/self_attention/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer_1/body/parallel_0/body/encoder/layer_3/self_attention/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer_1/body/parallel_0/body/encoder/layer_3/self_attention/multihead_attention/q/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/body/parallel_0/body/encoder/layer_3/self_attention/multihead_attention/k/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/body/parallel_0/body/encoder/layer_3/self_attention/multihead_attention/v/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/body/parallel_0/body/encoder/layer_3/self_attention/multihead_attention/output_transform/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/body/parallel_0/body/encoder/layer_3/ffn/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer_1/body/parallel_0/body/encoder/layer_3/ffn/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer_1/body/parallel_0/body/encoder/layer_3/ffn/conv1/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/body/parallel_0/body/encoder/layer_3/ffn/conv1/BiasAdd/ReadVariableOp',\n",
       " 'transformer_1/body/parallel_0/body/encoder/layer_3/ffn/conv2/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/body/parallel_0/body/encoder/layer_3/ffn/conv2/BiasAdd/ReadVariableOp',\n",
       " 'transformer_1/body/parallel_0/body/encoder/layer_4/self_attention/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer_1/body/parallel_0/body/encoder/layer_4/self_attention/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer_1/body/parallel_0/body/encoder/layer_4/self_attention/multihead_attention/q/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/body/parallel_0/body/encoder/layer_4/self_attention/multihead_attention/k/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/body/parallel_0/body/encoder/layer_4/self_attention/multihead_attention/v/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/body/parallel_0/body/encoder/layer_4/self_attention/multihead_attention/output_transform/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/body/parallel_0/body/encoder/layer_4/ffn/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer_1/body/parallel_0/body/encoder/layer_4/ffn/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer_1/body/parallel_0/body/encoder/layer_4/ffn/conv1/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/body/parallel_0/body/encoder/layer_4/ffn/conv1/BiasAdd/ReadVariableOp',\n",
       " 'transformer_1/body/parallel_0/body/encoder/layer_4/ffn/conv2/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/body/parallel_0/body/encoder/layer_4/ffn/conv2/BiasAdd/ReadVariableOp',\n",
       " 'transformer_1/body/parallel_0/body/encoder/layer_5/self_attention/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer_1/body/parallel_0/body/encoder/layer_5/self_attention/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer_1/body/parallel_0/body/encoder/layer_5/self_attention/multihead_attention/q/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/body/parallel_0/body/encoder/layer_5/self_attention/multihead_attention/k/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/body/parallel_0/body/encoder/layer_5/self_attention/multihead_attention/v/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/body/parallel_0/body/encoder/layer_5/self_attention/multihead_attention/output_transform/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/body/parallel_0/body/encoder/layer_5/ffn/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer_1/body/parallel_0/body/encoder/layer_5/ffn/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer_1/body/parallel_0/body/encoder/layer_5/ffn/conv1/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/body/parallel_0/body/encoder/layer_5/ffn/conv1/BiasAdd/ReadVariableOp',\n",
       " 'transformer_1/body/parallel_0/body/encoder/layer_5/ffn/conv2/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/body/parallel_0/body/encoder/layer_5/ffn/conv2/BiasAdd/ReadVariableOp',\n",
       " 'transformer_1/body/parallel_0/body/encoder/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer_1/body/parallel_0/body/encoder/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer_1/body/decoder/layer_0/encdec_attention/multihead_attention/k/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/body/decoder/layer_0/encdec_attention/multihead_attention/v/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/body/decoder/layer_1/encdec_attention/multihead_attention/k/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/body/decoder/layer_1/encdec_attention/multihead_attention/v/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/body/decoder/layer_2/encdec_attention/multihead_attention/k/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/body/decoder/layer_2/encdec_attention/multihead_attention/v/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/body/decoder/layer_3/encdec_attention/multihead_attention/k/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/body/decoder/layer_3/encdec_attention/multihead_attention/v/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/body/decoder/layer_4/encdec_attention/multihead_attention/k/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/body/decoder/layer_4/encdec_attention/multihead_attention/v/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/body/decoder/layer_5/encdec_attention/multihead_attention/k/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/body/decoder/layer_5/encdec_attention/multihead_attention/v/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_0/self_attention/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_0/self_attention/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_0/self_attention/multihead_attention/q/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_0/self_attention/multihead_attention/k/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_0/self_attention/multihead_attention/v/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_0/self_attention/multihead_attention/output_transform/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_0/encdec_attention/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_0/encdec_attention/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_0/encdec_attention/multihead_attention/q/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_0/encdec_attention/multihead_attention/output_transform/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_0_1/ffn/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_0_1/ffn/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_0_1/ffn/conv1/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_0_1/ffn/conv1/BiasAdd/ReadVariableOp',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_0_1/ffn/conv2/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_0_1/ffn/conv2/BiasAdd/ReadVariableOp',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_1/self_attention/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_1/self_attention/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_1/self_attention/multihead_attention/q/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_1/self_attention/multihead_attention/k/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_1/self_attention/multihead_attention/v/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_1/self_attention/multihead_attention/output_transform/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_1/encdec_attention/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_1/encdec_attention/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_1/encdec_attention/multihead_attention/q/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_1/encdec_attention/multihead_attention/output_transform/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_1_1/ffn/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_1_1/ffn/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_1_1/ffn/conv1/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_1_1/ffn/conv1/BiasAdd/ReadVariableOp',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_1_1/ffn/conv2/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_1_1/ffn/conv2/BiasAdd/ReadVariableOp',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_2/self_attention/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_2/self_attention/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_2/self_attention/multihead_attention/q/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_2/self_attention/multihead_attention/k/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_2/self_attention/multihead_attention/v/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_2/self_attention/multihead_attention/output_transform/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_2/encdec_attention/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_2/encdec_attention/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_2/encdec_attention/multihead_attention/q/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_2/encdec_attention/multihead_attention/output_transform/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_2_1/ffn/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_2_1/ffn/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_2_1/ffn/conv1/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_2_1/ffn/conv1/BiasAdd/ReadVariableOp',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_2_1/ffn/conv2/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_2_1/ffn/conv2/BiasAdd/ReadVariableOp',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_3/self_attention/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_3/self_attention/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_3/self_attention/multihead_attention/q/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_3/self_attention/multihead_attention/k/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_3/self_attention/multihead_attention/v/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_3/self_attention/multihead_attention/output_transform/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_3/encdec_attention/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_3/encdec_attention/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_3/encdec_attention/multihead_attention/q/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_3/encdec_attention/multihead_attention/output_transform/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_3_1/ffn/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_3_1/ffn/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_3_1/ffn/conv1/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_3_1/ffn/conv1/BiasAdd/ReadVariableOp',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_3_1/ffn/conv2/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_3_1/ffn/conv2/BiasAdd/ReadVariableOp',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_4/self_attention/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_4/self_attention/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_4/self_attention/multihead_attention/q/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_4/self_attention/multihead_attention/k/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_4/self_attention/multihead_attention/v/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_4/self_attention/multihead_attention/output_transform/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_4/encdec_attention/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_4/encdec_attention/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_4/encdec_attention/multihead_attention/q/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_4/encdec_attention/multihead_attention/output_transform/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_4_1/ffn/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_4_1/ffn/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_4_1/ffn/conv1/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_4_1/ffn/conv1/BiasAdd/ReadVariableOp',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_4_1/ffn/conv2/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_4_1/ffn/conv2/BiasAdd/ReadVariableOp',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_5/self_attention/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_5/self_attention/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_5/self_attention/multihead_attention/q/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_5/self_attention/multihead_attention/k/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_5/self_attention/multihead_attention/v/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_5/self_attention/multihead_attention/output_transform/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_5/encdec_attention/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_5/encdec_attention/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_5/encdec_attention/multihead_attention/q/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_5/encdec_attention/multihead_attention/output_transform/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_5_1/ffn/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_5_1/ffn/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_5_1/ffn/conv1/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_5_1/ffn/conv1/BiasAdd/ReadVariableOp',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_5_1/ffn/conv2/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_5_1/ffn/conv2/BiasAdd/ReadVariableOp',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/target_space_embedding/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/encoder/layer_0/self_attention/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/encoder/layer_0/self_attention/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/encoder/layer_0/self_attention/multihead_attention/q/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/encoder/layer_0/self_attention/multihead_attention/k/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/encoder/layer_0/self_attention/multihead_attention/v/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/encoder/layer_0/self_attention/multihead_attention/output_transform/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/encoder/layer_0/ffn/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/encoder/layer_0/ffn/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/encoder/layer_0/ffn/conv1/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/encoder/layer_0/ffn/conv1/BiasAdd/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/encoder/layer_0/ffn/conv2/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/encoder/layer_0/ffn/conv2/BiasAdd/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/encoder/layer_1/self_attention/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/encoder/layer_1/self_attention/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/encoder/layer_1/self_attention/multihead_attention/q/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/encoder/layer_1/self_attention/multihead_attention/k/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/encoder/layer_1/self_attention/multihead_attention/v/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/encoder/layer_1/self_attention/multihead_attention/output_transform/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/encoder/layer_1/ffn/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/encoder/layer_1/ffn/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/encoder/layer_1/ffn/conv1/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/encoder/layer_1/ffn/conv1/BiasAdd/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/encoder/layer_1/ffn/conv2/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/encoder/layer_1/ffn/conv2/BiasAdd/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/encoder/layer_2/self_attention/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/encoder/layer_2/self_attention/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/encoder/layer_2/self_attention/multihead_attention/q/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/encoder/layer_2/self_attention/multihead_attention/k/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/encoder/layer_2/self_attention/multihead_attention/v/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/encoder/layer_2/self_attention/multihead_attention/output_transform/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/encoder/layer_2/ffn/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/encoder/layer_2/ffn/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/encoder/layer_2/ffn/conv1/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/encoder/layer_2/ffn/conv1/BiasAdd/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/encoder/layer_2/ffn/conv2/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/encoder/layer_2/ffn/conv2/BiasAdd/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/encoder/layer_3/self_attention/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/encoder/layer_3/self_attention/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/encoder/layer_3/self_attention/multihead_attention/q/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/encoder/layer_3/self_attention/multihead_attention/k/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/encoder/layer_3/self_attention/multihead_attention/v/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/encoder/layer_3/self_attention/multihead_attention/output_transform/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/encoder/layer_3/ffn/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/encoder/layer_3/ffn/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/encoder/layer_3/ffn/conv1/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/encoder/layer_3/ffn/conv1/BiasAdd/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/encoder/layer_3/ffn/conv2/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/encoder/layer_3/ffn/conv2/BiasAdd/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/encoder/layer_4/self_attention/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/encoder/layer_4/self_attention/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/encoder/layer_4/self_attention/multihead_attention/q/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/encoder/layer_4/self_attention/multihead_attention/k/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/encoder/layer_4/self_attention/multihead_attention/v/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/encoder/layer_4/self_attention/multihead_attention/output_transform/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/encoder/layer_4/ffn/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/encoder/layer_4/ffn/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/encoder/layer_4/ffn/conv1/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/encoder/layer_4/ffn/conv1/BiasAdd/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/encoder/layer_4/ffn/conv2/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/encoder/layer_4/ffn/conv2/BiasAdd/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/encoder/layer_5/self_attention/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/encoder/layer_5/self_attention/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/encoder/layer_5/self_attention/multihead_attention/q/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/encoder/layer_5/self_attention/multihead_attention/k/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/encoder/layer_5/self_attention/multihead_attention/v/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/encoder/layer_5/self_attention/multihead_attention/output_transform/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/encoder/layer_5/ffn/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/encoder/layer_5/ffn/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/encoder/layer_5/ffn/conv1/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/encoder/layer_5/ffn/conv1/BiasAdd/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/encoder/layer_5/ffn/conv2/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/encoder/layer_5/ffn/conv2/BiasAdd/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/encoder/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/encoder/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_0/self_attention/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_0/self_attention/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_0/self_attention/multihead_attention/q/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_0/self_attention/multihead_attention/k/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_0/self_attention/multihead_attention/v/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_0/self_attention/multihead_attention/output_transform/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_0/encdec_attention/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_0/encdec_attention/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_0/encdec_attention/multihead_attention/q/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_0/encdec_attention/multihead_attention/k/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_0/encdec_attention/multihead_attention/v/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_0/encdec_attention/multihead_attention/output_transform/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_0_1/ffn/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_0_1/ffn/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_0_1/ffn/conv1/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_0_1/ffn/conv1/BiasAdd/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_0_1/ffn/conv2/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_0_1/ffn/conv2/BiasAdd/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_1/self_attention/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_1/self_attention/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_1/self_attention/multihead_attention/q/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_1/self_attention/multihead_attention/k/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_1/self_attention/multihead_attention/v/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_1/self_attention/multihead_attention/output_transform/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_1/encdec_attention/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_1/encdec_attention/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_1/encdec_attention/multihead_attention/q/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_1/encdec_attention/multihead_attention/k/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_1/encdec_attention/multihead_attention/v/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_1/encdec_attention/multihead_attention/output_transform/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_1_1/ffn/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_1_1/ffn/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_1_1/ffn/conv1/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_1_1/ffn/conv1/BiasAdd/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_1_1/ffn/conv2/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_1_1/ffn/conv2/BiasAdd/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_2/self_attention/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_2/self_attention/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_2/self_attention/multihead_attention/q/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_2/self_attention/multihead_attention/k/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_2/self_attention/multihead_attention/v/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_2/self_attention/multihead_attention/output_transform/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_2/encdec_attention/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_2/encdec_attention/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_2/encdec_attention/multihead_attention/q/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_2/encdec_attention/multihead_attention/k/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_2/encdec_attention/multihead_attention/v/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_2/encdec_attention/multihead_attention/output_transform/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_2_1/ffn/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_2_1/ffn/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_2_1/ffn/conv1/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_2_1/ffn/conv1/BiasAdd/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_2_1/ffn/conv2/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_2_1/ffn/conv2/BiasAdd/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_3/self_attention/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_3/self_attention/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_3/self_attention/multihead_attention/q/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_3/self_attention/multihead_attention/k/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_3/self_attention/multihead_attention/v/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_3/self_attention/multihead_attention/output_transform/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_3/encdec_attention/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_3/encdec_attention/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_3/encdec_attention/multihead_attention/q/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_3/encdec_attention/multihead_attention/k/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_3/encdec_attention/multihead_attention/v/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_3/encdec_attention/multihead_attention/output_transform/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_3_1/ffn/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_3_1/ffn/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_3_1/ffn/conv1/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_3_1/ffn/conv1/BiasAdd/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_3_1/ffn/conv2/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_3_1/ffn/conv2/BiasAdd/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_4/self_attention/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_4/self_attention/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_4/self_attention/multihead_attention/q/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_4/self_attention/multihead_attention/k/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_4/self_attention/multihead_attention/v/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_4/self_attention/multihead_attention/output_transform/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_4/encdec_attention/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_4/encdec_attention/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_4/encdec_attention/multihead_attention/q/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_4/encdec_attention/multihead_attention/k/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_4/encdec_attention/multihead_attention/v/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_4/encdec_attention/multihead_attention/output_transform/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_4_1/ffn/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_4_1/ffn/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_4_1/ffn/conv1/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_4_1/ffn/conv1/BiasAdd/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_4_1/ffn/conv2/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_4_1/ffn/conv2/BiasAdd/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_5/self_attention/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_5/self_attention/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_5/self_attention/multihead_attention/q/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_5/self_attention/multihead_attention/k/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_5/self_attention/multihead_attention/v/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_5/self_attention/multihead_attention/output_transform/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_5/encdec_attention/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_5/encdec_attention/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_5/encdec_attention/multihead_attention/q/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_5/encdec_attention/multihead_attention/k/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_5/encdec_attention/multihead_attention/v/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_5/encdec_attention/multihead_attention/output_transform/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_5_1/ffn/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_5_1/ffn/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_5_1/ffn/conv1/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_5_1/ffn/conv1/BiasAdd/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_5_1/ffn/conv2/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_5_1/ffn/conv2/BiasAdd/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'greedy',\n",
       " 'beam']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strings = ','.join(\n",
    "    [\n",
    "        n.name\n",
    "        for n in tf.get_default_graph().as_graph_def().node\n",
    "        if ('Variable' in n.op\n",
    "        or 'Placeholder' in n.name\n",
    "        or 'greedy' in n.name\n",
    "        or 'beam' in n.name\n",
    "        or 'alphas' in n.name\n",
    "        or 'self/Softmax' in n.name)\n",
    "        and 'adam' not in n.name\n",
    "        and 'beta' not in n.name\n",
    "        and 'global_step' not in n.name\n",
    "        and 'modality' not in n.name\n",
    "        and 'Assign' not in n.name\n",
    "    ]\n",
    ")\n",
    "strings.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_graph(model_dir, output_node_names):\n",
    "\n",
    "    if not tf.gfile.Exists(model_dir):\n",
    "        raise AssertionError(\n",
    "            \"Export directory doesn't exists. Please specify an export \"\n",
    "            'directory: %s' % model_dir\n",
    "        )\n",
    "\n",
    "    checkpoint = tf.train.get_checkpoint_state(model_dir)\n",
    "    input_checkpoint = checkpoint.model_checkpoint_path\n",
    "\n",
    "    absolute_model_dir = '/'.join(input_checkpoint.split('/')[:-1])\n",
    "    output_graph = absolute_model_dir + '/frozen_model.pb'\n",
    "    clear_devices = True\n",
    "    with tf.Session(graph = tf.Graph()) as sess:\n",
    "        saver = tf.train.import_meta_graph(\n",
    "            input_checkpoint + '.meta', clear_devices = clear_devices\n",
    "        )\n",
    "        saver.restore(sess, input_checkpoint)\n",
    "        output_graph_def = tf.graph_util.convert_variables_to_constants(\n",
    "            sess,\n",
    "            tf.get_default_graph().as_graph_def(),\n",
    "            output_node_names.split(','),\n",
    "        )\n",
    "        with tf.gfile.GFile(output_graph, 'wb') as f:\n",
    "            f.write(output_graph_def.SerializeToString())\n",
    "        print('%d ops in the final graph.' % len(output_graph_def.node))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from transformer-base/model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from transformer-base/model.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-16-9a7215a4e58a>:23: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-16-9a7215a4e58a>:23: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/husein/.local/lib/python3.6/site-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/husein/.local/lib/python3.6/site-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 201 variables.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 201 variables.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Converted 201 variables to const ops.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Converted 201 variables to const ops.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11006 ops in the final graph.\n"
     ]
    }
   ],
   "source": [
    "freeze_graph('transformer-base', strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_graph(frozen_graph_filename):\n",
    "    with tf.gfile.GFile(frozen_graph_filename, 'rb') as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "    with tf.Graph().as_default() as graph:\n",
    "        tf.import_graph_def(graph_def)\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/husein/.local/lib/python3.6/site-packages/tensorflow_core/python/client/session.py:1750: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    }
   ],
   "source": [
    "g = load_graph('transformer-base/frozen_model.pb')\n",
    "x = g.get_tensor_by_name('import/Placeholder:0')\n",
    "greedy = g.get_tensor_by_name('import/greedy:0')\n",
    "beam = g.get_tensor_by_name('import/beam:0')\n",
    "test_sess = tf.InteractiveSession(graph = g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "g, b = test_sess.run([greedy, beam], feed_dict = {x:encoded})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bermula tahun depan. bakal anggota polis perlu lulus ujian penilaian agama dan moral sebelum diterima bekerja, menurut PDRM yang bagi pastikan. Setiap anggotanya yang diambil bertugas mempunyai tahap integriti serta moral dan agama yang tinggi kerana anggota polis takkan dinilai masih hujan secara dalam talian dan temuduga bilangan mangsa banjir di Kota Tinggi, Johor naik dikit kepada hampir 720 Orang Sabah juga mula dilanda banjir menyaksikan hampir 400 penduduk di Sipitang, Beaufort dan Membakut berlindung di pusat pemindahan Kementerian Sumber Manusia bercadang memberikan insentif 500 sebulan kepada pekerja yang ikuti latihan kemahiran TVET, ia bertujuan menambah bilangan pekerja berkemahiran di negara ini dan cadangan itu akan dibentangkan kepada kabinet untuk kelulusan Wisma Putra memaklumkan adalah kerana Darat Malaysia maut dalam letusan ku number of Edward Island, New Zealand kelmarin belum dapat disahkan setakat ini. yang dapat disahkan adalah seorang Malaysia cedera dan kini kritikal dan di rawat di hospital kerajaan, penjawat awam kerajaan Perlis bakal terima bantuan khas kewangan 600 seseorang dan Barang akan dibuat Rabu minggu depan. beranikah berita hiburan kumpulan Stone mengakui kedudukan antara yang terbawah di pentas Maharaja Lawak Mega 2019 memberi tekanan kepada mereka, namun kumpulan itu memaklumkan Astro Gempak mereka lebih tertekan apabila menerima komen tidak membina daripada juri tu dia anggota yg Mamat Sepah, Aziz Senario dan Acong dan anda boleh tonton aksi mereka di pentas MLM 2019 siap Jumaat 9.00 malam di Astro Warna.',\n",
       " 'KUALA LUMPUR - Menteri di Jabatan Perdana Menteri, Datuk Seri Dr Mujahid Yusof Rawa hari ini mengakhiri lawatan kerja lapan hari ke Jordan, Turki dan Bosnia Herzegovina, lawatan yang bertujuan mengeratkan lagi hubungan dua hala dengan ketiga-tiga negara berkenaan.',\n",
       " 'KUALA LUMPUR - Menteri di Jabatan Perdana Menteri, Datuk Seri Dr Mujahid Yusof Rawa hari ini mengakhiri lawatan kerja lapan hari ke Jordan, Turki dan Bosnia Herzegovina, lawatan yang bertujuan mengeratkan lagi hubungan dua hala dengan ketiga-tiga negara berkenaan.',\n",
       " 'KUALA LUMPUR - Menteri di Jabatan Perdana Menteri, Datuk Seri Dr Mujahid Yusof Rawa hari ini mengakhiri lawatan kerja lapan hari ke Jordan, Turki dan Bosnia Herzegovina, lawatan yang bertujuan mengeratkan lagi hubungan dua hala dengan ketiga-tiga negara berkenaan.']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.decode(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bermula tahun depan. bakal anggota polis perlu lulus ujian penilaian agama dan moral sebelum diterima bekerja, menurut PDRM yang bagi pastikan. Setiap anggotanya yang diambil bertugas mempunyai tahap integriti serta moral dan agama yang tinggi kerana anggota polis takkan dinilai masih hujan secara dalam talian dan temuduga bilangan mangsa banjir di Kota Tinggi, Johor naik dikit kepada hampir 720 Orang Sabah juga mula dilanda banjir menyaksikan hampir 400 penduduk di Sipitang, Beaufort dan Membakut berlindung di pusat pemindahan Kementerian Sumber Manusia bercadang memberikan insentif 500 sebulan kepada pekerja yang ikuti latihan kemahiran TVET, ia bertujuan menambah bilangan pekerja berkemahiran di negara ini dan cadangan itu akan dibentangkan kepada kabinet untuk kelulusan. Wisma Putra memaklumkan adalah kerana Darat Malaysia maut dalam letusan ku number of Edward Island, New Zealand kelmarin belum dapat disahkan setakat ini yang dapat disahkan adalah seorang Malaysia cedera dan kini kritikal dan di rawat di hospital kerajaan, penjawat awam kerajaan Perlis bakal terima bantuan khas kewangan 600 seseorang dan Barang akan dibuat Rabu minggu depan. beranikah berita hiburan kumpulan Stone mengakui kedudukan antara yang terbawah di pentas Maharaja Lawak Mega 2019 memberi tekanan kepada mereka namun kumpulan itu memaklumkan Astro Gempak mereka lebih tertekan apabila menerima komen tidak membina daripada juri tu dia anggota yg Mamat Sepah, Aziz Senario dan Acong dan anda boleh tonton aksi mereka di pentas MLM 2019 siap Jumaat 9.00 malam di Astro Warna.',\n",
       " 'KUALA LUMPUR - Menteri di Jabatan Perdana Menteri, Datuk Seri Dr Mujahid Yusof Rawa hari ini mengakhiri lawatan kerja lapan hari ke Jordan, Turki dan Bosnia Herzegovina, lawatan yang bertujuan mengeratkan lagi hubungan dua hala dengan ketiga-tiga negara berkenaan.',\n",
       " 'KUALA LUMPUR - Menteri di Jabatan Perdana Menteri, Datuk Seri Dr Mujahid Yusof Rawa hari ini mengakhiri lawatan kerja lapan hari ke Jordan, Turki dan Bosnia Herzegovina, lawatan yang bertujuan mengeratkan lagi hubungan dua hala dengan ketiga-tiga negara berkenaan.',\n",
       " 'KUALA LUMPUR - Menteri di Jabatan Perdana Menteri, Datuk Seri Dr Mujahid Yusof Rawa hari ini mengakhiri lawatan kerja lapan hari ke Jordan, Turki dan Bosnia Herzegovina, lawatan yang bertujuan mengeratkan lagi hubungan dua hala dengan ketiga-tiga negara berkenaan.']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.decode(b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
