{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24ae5547",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3395870c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-17 23:59:16.100973: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-17 23:59:16.132217: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-17 23:59:16.133496: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-17 23:59:16.157054: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-07-17 23:59:16.160167: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-17 23:59:16.164401: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-17 23:59:16.166074: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-17 23:59:20.462487: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-17 23:59:20.463180: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-17 23:59:20.463864: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-07-17 23:59:20.464519: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2022-07-17 23:59:20.464550: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20364 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090 Ti, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "/home/ubuntu/.local/lib/python3.8/site-packages/apex/pyprof/__init__.py:5: FutureWarning: pyprof will be removed by the end of June, 2022\n",
      "  warnings.warn(\"pyprof will be removed by the end of June, 2022\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5Config, TFT5Model, T5Model, load_tf_weights_in_t5, T5Tokenizer\n",
    "from transformers import T5ForConditionalGeneration, TFT5ForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51fbf230",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a541b0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "out = 'temp'\n",
    "os.makedirs(out, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48753c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = T5Config.from_pretrained('malay-huggingface/t5-super-tiny-bahasa-cased')\n",
    "config.save_pretrained(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50a47b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint\r\n",
      "events.out.tfevents.1657649099.huseincomel-desktop\r\n",
      "events.out.tfevents.1657649245.huseincomel-desktop\r\n",
      "events.out.tfevents.1657675666.huseincomel-desktop\r\n",
      "events.out.tfevents.1657699724.huseincomel-desktop\r\n",
      "events.out.tfevents.1657709978.huseincomel-desktop\r\n",
      "events.out.tfevents.1657759870.huseincomel-desktop\r\n",
      "events.out.tfevents.1657772727.huseincomel-desktop\r\n",
      "events.out.tfevents.1657785835.huseincomel-desktop\r\n",
      "events.out.tfevents.1657879851.huseincomel-desktop\r\n",
      "events.out.tfevents.1658038720.huseincomel-desktop\r\n",
      "graph.pbtxt\r\n",
      "model.ckpt-1026000.data-00000-of-00002\r\n",
      "model.ckpt-1026000.data-00001-of-00002\r\n",
      "model.ckpt-1026000.index\r\n",
      "model.ckpt-1026000.meta\r\n",
      "model.ckpt-1066000.data-00000-of-00002\r\n",
      "model.ckpt-1066000.data-00001-of-00002\r\n",
      "model.ckpt-1066000.index\r\n",
      "model.ckpt-1066000.meta\r\n",
      "model.ckpt-1276000.data-00000-of-00002\r\n",
      "model.ckpt-1276000.data-00001-of-00002\r\n",
      "model.ckpt-1276000.index\r\n",
      "model.ckpt-1276000.meta\r\n",
      "model.ckpt-1396000.data-00000-of-00002\r\n",
      "model.ckpt-1396000.data-00001-of-00002\r\n",
      "model.ckpt-1396000.index\r\n",
      "model.ckpt-1396000.meta\r\n",
      "model.ckpt-1436000.data-00000-of-00002\r\n",
      "model.ckpt-1436000.data-00001-of-00002\r\n",
      "model.ckpt-1436000.index\r\n",
      "model.ckpt-1436000.meta\r\n",
      "model.ckpt-1476000.data-00000-of-00002\r\n",
      "model.ckpt-1476000.data-00001-of-00002\r\n",
      "model.ckpt-1476000.index\r\n",
      "model.ckpt-1476000.meta\r\n",
      "model.ckpt-1506000.data-00000-of-00002\r\n",
      "model.ckpt-1506000.data-00001-of-00002\r\n",
      "model.ckpt-1506000.index\r\n",
      "model.ckpt-1506000.meta\r\n",
      "model.ckpt-1516000.data-00000-of-00002\r\n",
      "model.ckpt-1516000.data-00001-of-00002\r\n",
      "model.ckpt-1516000.index\r\n",
      "model.ckpt-1516000.meta\r\n",
      "model.ckpt-1526000.data-00000-of-00002\r\n",
      "model.ckpt-1526000.data-00001-of-00002\r\n",
      "model.ckpt-1526000.index\r\n",
      "model.ckpt-1526000.meta\r\n",
      "model.ckpt-1536000.data-00000-of-00002\r\n",
      "model.ckpt-1536000.data-00001-of-00002\r\n",
      "model.ckpt-1536000.index\r\n",
      "model.ckpt-1536000.meta\r\n",
      "model.ckpt-1546000.data-00000-of-00002\r\n",
      "model.ckpt-1546000.data-00001-of-00002\r\n",
      "model.ckpt-1546000.index\r\n",
      "model.ckpt-1546000.meta\r\n",
      "model.ckpt-876000.data-00000-of-00002\r\n",
      "model.ckpt-876000.data-00001-of-00002\r\n",
      "model.ckpt-876000.index\r\n",
      "model.ckpt-876000.meta\r\n",
      "operative_config.gin\r\n"
     ]
    }
   ],
   "source": [
    "!ls t5-super-tiny-noisy-ms-en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f54394ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5Model(\n",
       "  (shared): Embedding(32128, 256)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 256)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=256, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=256, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=256, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=256, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 6)\n",
       "            )\n",
       "            (layer_norm): FusedRMSNorm(torch.Size([256]), eps=1e-06, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=256, out_features=1024, bias=False)\n",
       "              (wo): Linear(in_features=1024, out_features=256, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (relu_act): ReLU()\n",
       "            )\n",
       "            (layer_norm): FusedRMSNorm(torch.Size([256]), eps=1e-06, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=256, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=256, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=256, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=256, bias=False)\n",
       "            )\n",
       "            (layer_norm): FusedRMSNorm(torch.Size([256]), eps=1e-06, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=256, out_features=1024, bias=False)\n",
       "              (wo): Linear(in_features=1024, out_features=256, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (relu_act): ReLU()\n",
       "            )\n",
       "            (layer_norm): FusedRMSNorm(torch.Size([256]), eps=1e-06, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): FusedRMSNorm(torch.Size([256]), eps=1e-06, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 256)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=256, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=256, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=256, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=256, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 6)\n",
       "            )\n",
       "            (layer_norm): FusedRMSNorm(torch.Size([256]), eps=1e-06, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=256, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=256, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=256, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=256, bias=False)\n",
       "            )\n",
       "            (layer_norm): FusedRMSNorm(torch.Size([256]), eps=1e-06, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=256, out_features=1024, bias=False)\n",
       "              (wo): Linear(in_features=1024, out_features=256, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (relu_act): ReLU()\n",
       "            )\n",
       "            (layer_norm): FusedRMSNorm(torch.Size([256]), eps=1e-06, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=256, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=256, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=256, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=256, bias=False)\n",
       "            )\n",
       "            (layer_norm): FusedRMSNorm(torch.Size([256]), eps=1e-06, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=256, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=256, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=256, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=256, bias=False)\n",
       "            )\n",
       "            (layer_norm): FusedRMSNorm(torch.Size([256]), eps=1e-06, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=256, out_features=1024, bias=False)\n",
       "              (wo): Linear(in_features=1024, out_features=256, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (relu_act): ReLU()\n",
       "            )\n",
       "            (layer_norm): FusedRMSNorm(torch.Size([256]), eps=1e-06, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): FusedRMSNorm(torch.Size([256]), eps=1e-06, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = T5Model(config)\n",
    "load_tf_weights_in_t5(model, config, 't5-super-tiny-noisy-ms-en/model.ckpt-1536000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "faf936d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mkdir temp-t5-tiny\n",
    "# !cp t5-tiny-noisy-ms-en/model.ckpt-1361000* temp-t5-tiny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86b9d748",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tokenizer = T5Tokenizer('sp10m.cased.ms-en.model', padding = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e68dcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "737e7c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gen = T5ForConditionalGeneration.from_pretrained(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "005b412a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-17 23:59:22.490334: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "2022-07-17 23:59:23.142603: I tensorflow/stream_executor/cuda/cuda_blas.cc:1760] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFT5ForConditionalGeneration: ['decoder.embed_tokens.weight', 'encoder.embed_tokens.weight']\n",
      "- This IS expected if you are initializing TFT5ForConditionalGeneration from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFT5ForConditionalGeneration from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFT5ForConditionalGeneration were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model_tf = TFT5ForConditionalGeneration.from_pretrained(out, from_pt = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc1a66fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ms-en-right.test') as fopen:\n",
    "    right = fopen.read().split('\\n')\n",
    "    \n",
    "with open('ms-en-left.test') as fopen:\n",
    "    left = fopen.read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3124e42d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 256)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 256)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=256, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=256, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=256, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=256, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 6)\n",
       "            )\n",
       "            (layer_norm): FusedRMSNorm(torch.Size([256]), eps=1e-06, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=256, out_features=1024, bias=False)\n",
       "              (wo): Linear(in_features=1024, out_features=256, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (relu_act): ReLU()\n",
       "            )\n",
       "            (layer_norm): FusedRMSNorm(torch.Size([256]), eps=1e-06, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=256, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=256, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=256, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=256, bias=False)\n",
       "            )\n",
       "            (layer_norm): FusedRMSNorm(torch.Size([256]), eps=1e-06, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=256, out_features=1024, bias=False)\n",
       "              (wo): Linear(in_features=1024, out_features=256, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (relu_act): ReLU()\n",
       "            )\n",
       "            (layer_norm): FusedRMSNorm(torch.Size([256]), eps=1e-06, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): FusedRMSNorm(torch.Size([256]), eps=1e-06, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 256)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=256, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=256, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=256, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=256, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 6)\n",
       "            )\n",
       "            (layer_norm): FusedRMSNorm(torch.Size([256]), eps=1e-06, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=256, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=256, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=256, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=256, bias=False)\n",
       "            )\n",
       "            (layer_norm): FusedRMSNorm(torch.Size([256]), eps=1e-06, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=256, out_features=1024, bias=False)\n",
       "              (wo): Linear(in_features=1024, out_features=256, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (relu_act): ReLU()\n",
       "            )\n",
       "            (layer_norm): FusedRMSNorm(torch.Size([256]), eps=1e-06, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=256, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=256, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=256, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=256, bias=False)\n",
       "            )\n",
       "            (layer_norm): FusedRMSNorm(torch.Size([256]), eps=1e-06, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=256, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=256, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=256, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=256, bias=False)\n",
       "            )\n",
       "            (layer_norm): FusedRMSNorm(torch.Size([256]), eps=1e-06, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=256, out_features=1024, bias=False)\n",
       "              (wo): Linear(in_features=1024, out_features=256, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (relu_act): ReLU()\n",
       "            )\n",
       "            (layer_norm): FusedRMSNorm(torch.Size([256]), eps=1e-06, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): FusedRMSNorm(torch.Size([256]), eps=1e-06, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=256, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gen.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "35abd80e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5475/5475 [26:12<00:00,  3.48it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "results = []\n",
    "for i in tqdm(range(0, len(left), batch_size)):\n",
    "    input_ids = [{'input_ids': tokenizer.encode(f'terjemah Melayu ke Inggeris: {s}', return_tensors = 'pt')[0]} for s in left[i:i + batch_size]]\n",
    "    padded = tokenizer.pad(input_ids, padding = 'longest')\n",
    "    outputs = model_gen.generate(padded['input_ids'].cuda(), attention_mask = padded['attention_mask'].cuda(), max_length = 1000)\n",
    "    # outputs = model_gen.generate(**padded, max_length = 1000)\n",
    "    for o in outputs:\n",
    "        results.append(tokenizer.decode(o, skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb550d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sacrebleu.metrics import BLEU, CHRF, TER\n",
    "\n",
    "bleu = BLEU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "20530f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_left, filtered_right = [], []\n",
    "for no, r in enumerate(results):\n",
    "    if len(r):\n",
    "        filtered_left.append(r)\n",
    "        filtered_right.append(right[no])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e50b3fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "refs = [filtered_right]\n",
    "sys = filtered_left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e5d6f81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = bleu.corpus_score(sys, refs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cf03103f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'BLEU',\n",
       " 'score': 59.92897086989418,\n",
       " '_mean': -1.0,\n",
       " '_ci': -1.0,\n",
       " '_verbose': '79.8/64.0/54.1/46.6 (BP = 1.000 ratio = 1.008 hyp_len = 2017101 ref_len = 2001100)',\n",
       " 'bp': 1.0,\n",
       " 'counts': [1609890, 1235532, 997094, 818350],\n",
       " 'totals': [2017101, 1929506, 1842087, 1755069],\n",
       " 'sys_len': 2017101,\n",
       " 'ref_len': 2001100,\n",
       " 'precisions': [79.81206692178527,\n",
       "  64.03359201785328,\n",
       "  54.12849664538103,\n",
       "  46.62779640002758],\n",
       " 'prec_str': '79.8/64.0/54.1/46.6',\n",
       " 'ratio': 1.0079961021438208}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "88704b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.push_to_hub('t5-super-tiny-finetuned-noisy-ms-en', organization='mesolitica')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "97afc0d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1567b9e19e7243afaebbea48e91bdae1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file pytorch_model.bin:   0%|          | 4.00k/48.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://huggingface.co/mesolitica/t5-super-tiny-finetuned-noisy-ms-en\n",
      "   a3c245b..3938ef1  main -> main\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://huggingface.co/mesolitica/t5-super-tiny-finetuned-noisy-ms-en/commit/3938ef128a6443a39c9080ed8707caa469ebff80'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gen.push_to_hub('t5-super-tiny-finetuned-noisy-ms-en', organization='mesolitica')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "db817c07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01b552393cf846b98c5363bfbbd567d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload file tf_model.h5:   0%|          | 4.00k/48.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://huggingface.co/mesolitica/t5-super-tiny-finetuned-noisy-ms-en\n",
      "   3938ef1..55bf7e1  main -> main\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://huggingface.co/mesolitica/t5-super-tiny-finetuned-noisy-ms-en/commit/55bf7e1cf8368b459f0f823e1b457d16f9142aa4'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_tf.push_to_hub('t5-super-tiny-finetuned-noisy-ms-en', organization='mesolitica',\n",
    "                    tags = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2819f991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already up to date.\r\n"
     ]
    }
   ],
   "source": [
    "!cd t5-super-tiny-finetuned-noisy-ms-en && git pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "df9b8117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main 37cbc88] add tensorboard\n",
      " 1 file changed, 2 insertions(+), 2 deletions(-)\n",
      "Uploading LFS objects: 100% (1/1), 40 MB | 1.9 MB/s, done.                      \n",
      "Enumerating objects: 5, done.\n",
      "Counting objects: 100% (5/5), done.\n",
      "Delta compression using up to 16 threads\n",
      "Compressing objects: 100% (3/3), done.\n",
      "Writing objects: 100% (3/3), 378 bytes | 378.00 KiB/s, done.\n",
      "Total 3 (delta 1), reused 0 (delta 0)\n",
      "To https://huggingface.co/mesolitica/t5-super-tiny-finetuned-noisy-ms-en\n",
      "   55bf7e1..37cbc88  main -> main\n"
     ]
    }
   ],
   "source": [
    "!cp t5-super-tiny-noisy-ms-en/*.tfevents.* t5-super-tiny-finetuned-noisy-ms-en\n",
    "!cd t5-super-tiny-finetuned-noisy-ms-en && git add . && git commit -m 'add tensorboard' && git push"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
