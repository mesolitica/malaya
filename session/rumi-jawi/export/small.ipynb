{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96f75082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !~/tf-nvidia/bin/pip3 install git+https://github.com/huseinzol05/tensor2tensor.git --no-deps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d84f7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70878542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-02 14:57:43.890732: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/tf-nvidia/lib/python3.8/site-packages/tensorflow_gan/python/estimator/tpu_gan_estimator.py:42: The name tf.estimator.tpu.TPUEstimator is deprecated. Please use tf.compat.v1.estimator.tpu.TPUEstimator instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/tf-nvidia/lib/python3.8/site-packages/tensorflow_gan/python/estimator/tpu_gan_estimator.py:42: The name tf.estimator.tpu.TPUEstimator is deprecated. Please use tf.compat.v1.estimator.tpu.TPUEstimator instead.\n",
      "\n",
      "/home/ubuntu/tf-nvidia/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from tensor2tensor import models\n",
    "from tensor2tensor import problems\n",
    "from tensor2tensor.layers import common_layers\n",
    "from tensor2tensor.utils import trainer_lib\n",
    "from tensor2tensor.utils import t2t_model\n",
    "from tensor2tensor.utils import registry\n",
    "from tensor2tensor.utils import metrics\n",
    "from tensor2tensor.data_generators import problem\n",
    "from tensor2tensor.data_generators import text_problems\n",
    "from tensor2tensor.data_generators import translate\n",
    "from tensor2tensor.utils import registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93345c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import youtokentome as yttm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef9fc96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bpe = yttm.BPE(model='rumi-jawi.yttm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f16bb21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder:\n",
    "    def __init__(self, bpe):\n",
    "        self.bpe = bpe\n",
    "        self.vocab_size = len(self.bpe.vocab())\n",
    "\n",
    "    def encode(self, s):\n",
    "        s = self.bpe.encode(s, output_type=yttm.OutputType.ID)\n",
    "        s = [i + [1] for i in s]\n",
    "        return s\n",
    "\n",
    "    def decode(self, ids, strip_extraneous=False):\n",
    "        return self.bpe.decode(list(ids))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9995f8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@registry.register_problem\n",
    "class Jawi(text_problems.Text2TextProblem):\n",
    "    @property\n",
    "    def approx_vocab_size(self):\n",
    "        return 32000\n",
    "\n",
    "    @property\n",
    "    def is_generate_per_split(self):\n",
    "        # generate_data will shard the data into TRAIN and EVAL for us.\n",
    "        return False\n",
    "\n",
    "    @property\n",
    "    def dataset_splits(self):\n",
    "        return [\n",
    "            {'split': problem.DatasetSplit.TRAIN, 'shards': 200},\n",
    "            {'split': problem.DatasetSplit.EVAL, 'shards': 1},\n",
    "        ]\n",
    "\n",
    "    def feature_encoders(self, data_dir):\n",
    "        s_encoder = Encoder(bpe)\n",
    "        return {'inputs': s_encoder, 'targets': s_encoder}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cbcce204",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROBLEM = 'jawi'\n",
    "problem = problems.problem(PROBLEM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4eda98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, HPARAMS = \"transformer_small\", DATA_DIR = 't2t/data2'):\n",
    "        \n",
    "        self.X = tf.placeholder(tf.int32, [None, None])\n",
    "        self.Y = tf.placeholder(tf.int32, [None, None])\n",
    "        self.beam_size = tf.placeholder(tf.int32, shape=(), name = 'beam_size')\n",
    "        self.temperature = tf.placeholder(tf.float32, shape=(), name = 'temperature')\n",
    "        \n",
    "        self.X_seq_len = tf.count_nonzero(self.X, 1, dtype=tf.int32)\n",
    "        maxlen_decode = 50 + tf.reduce_max(self.X_seq_len)\n",
    "        \n",
    "        x = tf.expand_dims(tf.expand_dims(self.X, -1), -1)\n",
    "        y = tf.expand_dims(tf.expand_dims(self.Y, -1), -1)\n",
    "        \n",
    "        features = {\n",
    "            \"inputs\": x,\n",
    "            \"targets\": y,\n",
    "            \"target_space_id\": tf.constant(1, dtype=tf.int32),\n",
    "        }\n",
    "        print(features)\n",
    "        \n",
    "        Modes = tf.estimator.ModeKeys\n",
    "        hparams = trainer_lib.create_hparams(HPARAMS, data_dir=DATA_DIR, problem_name=PROBLEM)\n",
    "        translate_model = registry.model('transformer')(hparams, Modes.PREDICT)\n",
    "        logits, _ = translate_model(features)\n",
    "        \n",
    "        with tf.variable_scope(tf.get_variable_scope(), reuse=True):\n",
    "            self.fast_result = translate_model._greedy_infer(features, maxlen_decode)[\"outputs\"]\n",
    "            self.beam_result = translate_model._beam_decode_slow(\n",
    "                features, maxlen_decode, beam_size=self.beam_size, \n",
    "                top_beams=1, alpha=self.temperature)[\"outputs\"]\n",
    "        \n",
    "        self.fast_result = tf.identity(self.fast_result, name = 'greedy')\n",
    "        self.beam_result = tf.identity(self.beam_result, name = 'beam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1c3a277",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94f07cbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'t2t-rumi-jawi/small/model.ckpt-100000'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt_path = tf.train.latest_checkpoint('t2t-rumi-jawi/small')\n",
    "ckpt_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9db47e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_86718/1767067921.py:1: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_86718/1767067921.py:1: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_86718/1767067921.py:2: The name tf.InteractiveSession is deprecated. Please use tf.compat.v1.InteractiveSession instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_86718/1767067921.py:2: The name tf.InteractiveSession is deprecated. Please use tf.compat.v1.InteractiveSession instead.\n",
      "\n",
      "2022-08-02 14:57:50.062777: I tensorflow/core/platform/profile_utils/cpu_utils.cc:109] CPU Frequency: 2496000000 Hz\n",
      "2022-08-02 14:57:50.063125: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x588b000 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2022-08-02 14:57:50.063140: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2022-08-02 14:57:50.064391: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2022-08-02 14:57:50.154219: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1082] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-02 14:57:50.155021: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x3441d70 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2022-08-02 14:57:50.155034: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3090 Ti, Compute Capability 8.6\n",
      "2022-08-02 14:57:50.155167: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1082] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-02 14:57:50.155869: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1666] Found device 0 with properties: \n",
      "name: NVIDIA GeForce RTX 3090 Ti major: 8 minor: 6 memoryClockRate(GHz): 1.86\n",
      "pciBusID: 0000:01:00.0\n",
      "2022-08-02 14:57:50.155890: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-08-02 14:57:50.158323: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2022-08-02 14:57:50.175119: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-08-02 14:57:50.175299: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-08-02 14:57:50.175632: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.11\n",
      "2022-08-02 14:57:50.176081: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2022-08-02 14:57:50.176149: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2022-08-02 14:57:50.176219: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1082] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-02 14:57:50.176959: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1082] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-02 14:57:50.177635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1794] Adding visible gpu devices: 0\n",
      "2022-08-02 14:57:50.177654: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_86718/1724356959.py:4: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-02 14:57:50.375483: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1206] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-08-02 14:57:50.375511: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1212]      0 \n",
      "2022-08-02 14:57:50.375515: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1225] 0:   N \n",
      "2022-08-02 14:57:50.375681: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1082] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-02 14:57:50.376424: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1082] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-02 14:57:50.377122: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1351] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 20283 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 3090 Ti, pci bus id: 0000:01:00.0, compute capability: 8.6)\n",
      "WARNING:tensorflow:From /tmp/ipykernel_86718/1724356959.py:4: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'inputs': <tf.Tensor 'ExpandDims_1:0' shape=(?, ?, 1, 1) dtype=int32>, 'targets': <tf.Tensor 'ExpandDims_3:0' shape=(?, ?, 1, 1) dtype=int32>, 'target_space_id': <tf.Tensor 'Const_1:0' shape=() dtype=int32>}\n",
      "INFO:tensorflow:Setting T2TModel mode to 'infer'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting T2TModel mode to 'infer'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting hparams.dropout to 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting hparams.label_smoothing to 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting hparams.layer_prepostprocess_dropout to 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting hparams.symbol_dropout to 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting hparams.attention_dropout to 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Setting hparams.relu_dropout to 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function framework at 0x7efbf2c3eaf0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: LIVE_VARS_IN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function framework at 0x7efbf2c3eaf0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: LIVE_VARS_IN\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <function framework at 0x7efbf2c3eaf0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: LIVE_VARS_IN\n",
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_32000_256.bottom\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_32000_256.bottom\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_32000_256.targets_bottom\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_32000_256.targets_bottom\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Building model body\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Building model body\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function attention_bias_to_padding at 0x7efbf1501ca0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function attention_bias_to_padding at 0x7efbf1501ca0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <function attention_bias_to_padding at 0x7efbf1501ca0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: \n",
      "WARNING:tensorflow:Entity <function layers at 0x7efc846d49d0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: If not matching a CFG node, must be a block statement: <gast.gast.ImportFrom object at 0x7efb682c7340>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function layers at 0x7efc846d49d0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: If not matching a CFG node, must be a block statement: <gast.gast.ImportFrom object at 0x7efb682c7340>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <function layers at 0x7efc846d49d0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: If not matching a CFG node, must be a block statement: <gast.gast.ImportFrom object at 0x7efb682c7340>\n",
      "INFO:tensorflow:Transforming body output with symbol_modality_32000_256.top\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Transforming body output with symbol_modality_32000_256.top\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_86718/1724356959.py:27: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_86718/1724356959.py:27: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_86718/1724356959.py:27: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_86718/1724356959.py:27: The name tf.get_variable_scope is deprecated. Please use tf.compat.v1.get_variable_scope instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using variable initializer: uniform_unit_scaling\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_32000_256.bottom\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Transforming feature 'inputs' with symbol_modality_32000_256.bottom\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_32000_256.targets_bottom\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Transforming feature 'targets' with symbol_modality_32000_256.targets_bottom\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Building model body\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Building model body\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Transforming body output with symbol_modality_32000_256.top\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Transforming body output with symbol_modality_32000_256.top\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "model = Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "acc7b987",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_86718/1982269191.py:1: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_86718/1982269191.py:1: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_86718/1982269191.py:1: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_86718/1982269191.py:1: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_86718/1982269191.py:2: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_86718/1982269191.py:2: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from t2t-rumi-jawi/small/model.ckpt-100000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from t2t-rumi-jawi/small/model.ckpt-100000\n"
     ]
    }
   ],
   "source": [
    "var_lists = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)\n",
    "saver = tf.train.Saver(var_list = var_lists)\n",
    "saver.restore(sess, ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "023412b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "train_X, train_Y = [], []\n",
    "with open('../jawi-rumi/jawi-rumi-news-full.test') as fopen:\n",
    "    for line in fopen:\n",
    "        d = json.loads(line)\n",
    "        train_Y.append(d[1])\n",
    "        train_X.append(d[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "199e0f44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['laporan sebuah portal berita baru-baru ini memetik seorang ahli parlimen pkr yang enggan dinamakan yang mendakwa azmin',\n",
       " 'isu bil tnb dibawa ke kabinet - saifuddin',\n",
       " 'dengan membuat sampel merasa kenyang lebih cepat.',\n",
       " 'banyak orang yang merasa takut bahwa ai akan menggeser peran manusia.',\n",
       " 'singapura, menurut kementerian transportasi singapura, tidak akan ragu untuk mengambil tindakan tegas atas aktivitas tersebut.']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b90917cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(bpe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "06df9165",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3494,\n",
       "  1223,\n",
       "  9869,\n",
       "  5732,\n",
       "  8213,\n",
       "  325,\n",
       "  25124,\n",
       "  1826,\n",
       "  1117,\n",
       "  1608,\n",
       "  6951,\n",
       "  217,\n",
       "  12107,\n",
       "  9526,\n",
       "  217,\n",
       "  6700,\n",
       "  13566,\n",
       "  1]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.encode([train_X[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "91a7a3cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-02 14:58:08.965217: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('لاڤورن سبواه ڤورتل بريتا بارو-بارو اين ممتيق سأورڠ اهلي ڤرليمين ڤقر يڠ اڠڬن ديناماكن يڠ مندعوا عزمين<UNK>',\n",
       " 'لاڤورن سبواه ڤورتل بريتا بارو-بارو اين ممتيق سأورڠ اهلي ڤرليمين ڤقر يڠ اڠڬن ديناماكن يڠ مندعوا عزمين<UNK>')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string = train_X[0]\n",
    "encoded = encoder.encode([string])\n",
    "f, b = sess.run([model.fast_result, model.beam_result], feed_dict = {model.X: encoded, model.temperature: 0.5,\n",
    "                                                                    model.beam_size: 2})\n",
    "encoder.decode(f[0].tolist()), encoder.decode(b[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e5a93fc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ايسو بيل تنب دباوا ك كابينيت - صيفالدين<UNK>',\n",
       " 'ايسو بيل تنب دباوا ك كابينيت - صيفالدين<UNK>')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string = train_X[1]\n",
    "encoded = encoder.encode([string])\n",
    "f, b = sess.run([model.fast_result, model.beam_result], feed_dict = {model.X: encoded, model.temperature: 0.5,\n",
    "                                                                    model.beam_size: 2})\n",
    "encoder.decode(f[0].tolist()), encoder.decode(b[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dc63b6f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('دڠن ممبوات سمڤل مراسا كينياڠ لبيه چڤت.<UNK>',\n",
       " 'دڠن ممبوات سمڤل مراسا كينياڠ لبيه چڤت.<UNK>')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string = train_X[2]\n",
    "encoded = encoder.encode([string])\n",
    "f, b = sess.run([model.fast_result, model.beam_result], feed_dict = {model.X: encoded, model.temperature: 0.5,\n",
    "                                                                    model.beam_size: 2})\n",
    "encoder.decode(f[0].tolist()), encoder.decode(b[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fd266a8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[358, 2170, 20123, 17179, 10285, 38, 696, 7991, 46]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f[0][f[0] > 3].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2ac61d29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<PAD><UNK><BOS><EOS>'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.decode([0,1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7c289c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cer(actual, hyp):\n",
    "    \"\"\"\n",
    "    Calculate CER using `python-Levenshtein`.\n",
    "    \"\"\"\n",
    "    import Levenshtein as Lev\n",
    "\n",
    "    actual = actual.replace(' ', '')\n",
    "    hyp = hyp.replace(' ', '')\n",
    "    return Lev.distance(actual, hyp) / len(actual)\n",
    "\n",
    "\n",
    "def calculate_wer(actual, hyp):\n",
    "    \"\"\"\n",
    "    Calculate WER using `python-Levenshtein`.\n",
    "    \"\"\"\n",
    "    import Levenshtein as Lev\n",
    "\n",
    "    b = set(actual.split() + hyp.split())\n",
    "    word2char = dict(zip(b, range(len(b))))\n",
    "\n",
    "    w1 = [chr(word2char[w]) for w in actual.split()]\n",
    "    w2 = [chr(word2char[w]) for w in hyp.split()]\n",
    "\n",
    "    return Lev.distance(''.join(w1), ''.join(w2)) / len(actual.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7280c804",
   "metadata": {},
   "outputs": [],
   "source": [
    "string = train_X[1]\n",
    "encoded = encoder.encode([string])\n",
    "f = sess.run(model.fast_result, feed_dict = {model.X: encoded})[0]\n",
    "p = encoder.decode(f[f > 3].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6e35bbbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 0.0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_cer(train_Y[1], p), calculate_wer(train_Y[1], p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f64b64b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████| 10000/10000 [16:02<00:00, 10.39it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "cers, wers = [], []\n",
    "for i in tqdm(range(len(train_X[:10000]))):\n",
    "    string = train_X[i]\n",
    "    encoded = encoder.encode([string])\n",
    "    f = sess.run(model.fast_result, feed_dict = {model.X: encoded})[0]\n",
    "    p = encoder.decode(f[f > 3].tolist())\n",
    "    cer, wer = calculate_cer(train_Y[i], p), calculate_wer(train_Y[i], p)\n",
    "    cers.append(cer)\n",
    "    wers.append(wer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dd4d9e5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0006167541656054869, 0.0019283112815117458)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.mean(cers), np.mean(wers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3c66f5d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_86718/1157229290.py:1: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_86718/1157229290.py:1: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'rumi-jawi-small/model.ckpt'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saver = tf.train.Saver(tf.trainable_variables())\n",
    "saver.save(sess, 'rumi-jawi-small/model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9134baf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_86718/299983990.py:4: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_86718/299983990.py:4: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Placeholder',\n",
       " 'Placeholder_1',\n",
       " 'beam_size',\n",
       " 'temperature',\n",
       " 'transformer/body/target_space_embedding/kernel/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/target_space_embedding/ReadVariableOp',\n",
       " 'transformer/body/encoder/layer_0/self_attention/layer_prepostprocess/layer_norm/layer_norm_scale/Read/ReadVariableOp',\n",
       " 'transformer/body/encoder/layer_0/self_attention/layer_prepostprocess/layer_norm/layer_norm_bias/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/encoder/layer_0/self_attention/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/encoder/layer_0/self_attention/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer/body/encoder/layer_0/self_attention/multihead_attention/q/kernel/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/encoder/layer_0/self_attention/multihead_attention/q/Tensordot/ReadVariableOp',\n",
       " 'transformer/body/encoder/layer_0/self_attention/multihead_attention/k/kernel/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/encoder/layer_0/self_attention/multihead_attention/k/Tensordot/ReadVariableOp',\n",
       " 'transformer/body/encoder/layer_0/self_attention/multihead_attention/v/kernel/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/encoder/layer_0/self_attention/multihead_attention/v/Tensordot/ReadVariableOp',\n",
       " 'transformer/body/encoder/layer_0/self_attention/multihead_attention/output_transform/kernel/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/encoder/layer_0/self_attention/multihead_attention/output_transform/Tensordot/ReadVariableOp',\n",
       " 'transformer/body/encoder/layer_0/ffn/layer_prepostprocess/layer_norm/layer_norm_scale/Read/ReadVariableOp',\n",
       " 'transformer/body/encoder/layer_0/ffn/layer_prepostprocess/layer_norm/layer_norm_bias/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/encoder/layer_0/ffn/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/encoder/layer_0/ffn/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer/body/encoder/layer_0/ffn/conv1/kernel/Read/ReadVariableOp',\n",
       " 'transformer/body/encoder/layer_0/ffn/conv1/bias/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/encoder/layer_0/ffn/conv1/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/encoder/layer_0/ffn/conv1/BiasAdd/ReadVariableOp',\n",
       " 'transformer/body/encoder/layer_0/ffn/conv2/kernel/Read/ReadVariableOp',\n",
       " 'transformer/body/encoder/layer_0/ffn/conv2/bias/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/encoder/layer_0/ffn/conv2/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/encoder/layer_0/ffn/conv2/BiasAdd/ReadVariableOp',\n",
       " 'transformer/body/encoder/layer_1/self_attention/layer_prepostprocess/layer_norm/layer_norm_scale/Read/ReadVariableOp',\n",
       " 'transformer/body/encoder/layer_1/self_attention/layer_prepostprocess/layer_norm/layer_norm_bias/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/encoder/layer_1/self_attention/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/encoder/layer_1/self_attention/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer/body/encoder/layer_1/self_attention/multihead_attention/q/kernel/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/encoder/layer_1/self_attention/multihead_attention/q/Tensordot/ReadVariableOp',\n",
       " 'transformer/body/encoder/layer_1/self_attention/multihead_attention/k/kernel/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/encoder/layer_1/self_attention/multihead_attention/k/Tensordot/ReadVariableOp',\n",
       " 'transformer/body/encoder/layer_1/self_attention/multihead_attention/v/kernel/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/encoder/layer_1/self_attention/multihead_attention/v/Tensordot/ReadVariableOp',\n",
       " 'transformer/body/encoder/layer_1/self_attention/multihead_attention/output_transform/kernel/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/encoder/layer_1/self_attention/multihead_attention/output_transform/Tensordot/ReadVariableOp',\n",
       " 'transformer/body/encoder/layer_1/ffn/layer_prepostprocess/layer_norm/layer_norm_scale/Read/ReadVariableOp',\n",
       " 'transformer/body/encoder/layer_1/ffn/layer_prepostprocess/layer_norm/layer_norm_bias/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/encoder/layer_1/ffn/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/encoder/layer_1/ffn/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer/body/encoder/layer_1/ffn/conv1/kernel/Read/ReadVariableOp',\n",
       " 'transformer/body/encoder/layer_1/ffn/conv1/bias/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/encoder/layer_1/ffn/conv1/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/encoder/layer_1/ffn/conv1/BiasAdd/ReadVariableOp',\n",
       " 'transformer/body/encoder/layer_1/ffn/conv2/kernel/Read/ReadVariableOp',\n",
       " 'transformer/body/encoder/layer_1/ffn/conv2/bias/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/encoder/layer_1/ffn/conv2/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/encoder/layer_1/ffn/conv2/BiasAdd/ReadVariableOp',\n",
       " 'transformer/body/encoder/layer_prepostprocess/layer_norm/layer_norm_scale/Read/ReadVariableOp',\n",
       " 'transformer/body/encoder/layer_prepostprocess/layer_norm/layer_norm_bias/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/encoder/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/encoder/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer/body/decoder/layer_0/self_attention/layer_prepostprocess/layer_norm/layer_norm_scale/Read/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_0/self_attention/layer_prepostprocess/layer_norm/layer_norm_bias/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_0/self_attention/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_0/self_attention/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer/body/decoder/layer_0/self_attention/multihead_attention/q/kernel/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_0/self_attention/multihead_attention/q/Tensordot/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_0/self_attention/multihead_attention/k/kernel/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_0/self_attention/multihead_attention/k/Tensordot/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_0/self_attention/multihead_attention/v/kernel/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_0/self_attention/multihead_attention/v/Tensordot/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_0/self_attention/multihead_attention/output_transform/kernel/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_0/self_attention/multihead_attention/output_transform/Tensordot/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_0/encdec_attention/layer_prepostprocess/layer_norm/layer_norm_scale/Read/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_0/encdec_attention/layer_prepostprocess/layer_norm/layer_norm_bias/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_0/encdec_attention/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_0/encdec_attention/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer/body/decoder/layer_0/encdec_attention/multihead_attention/q/kernel/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_0/encdec_attention/multihead_attention/q/Tensordot/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_0/encdec_attention/multihead_attention/k/kernel/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_0/encdec_attention/multihead_attention/k/Tensordot/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_0/encdec_attention/multihead_attention/v/kernel/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_0/encdec_attention/multihead_attention/v/Tensordot/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_0/encdec_attention/multihead_attention/output_transform/kernel/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_0/encdec_attention/multihead_attention/output_transform/Tensordot/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_0/ffn/layer_prepostprocess/layer_norm/layer_norm_scale/Read/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_0/ffn/layer_prepostprocess/layer_norm/layer_norm_bias/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_0_1/ffn/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_0_1/ffn/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer/body/decoder/layer_0/ffn/conv1/kernel/Read/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_0/ffn/conv1/bias/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_0_1/ffn/conv1/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_0_1/ffn/conv1/BiasAdd/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_0/ffn/conv2/kernel/Read/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_0/ffn/conv2/bias/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_0_1/ffn/conv2/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_0_1/ffn/conv2/BiasAdd/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_1/self_attention/layer_prepostprocess/layer_norm/layer_norm_scale/Read/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_1/self_attention/layer_prepostprocess/layer_norm/layer_norm_bias/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_1/self_attention/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_1/self_attention/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer/body/decoder/layer_1/self_attention/multihead_attention/q/kernel/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_1/self_attention/multihead_attention/q/Tensordot/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_1/self_attention/multihead_attention/k/kernel/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_1/self_attention/multihead_attention/k/Tensordot/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_1/self_attention/multihead_attention/v/kernel/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_1/self_attention/multihead_attention/v/Tensordot/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_1/self_attention/multihead_attention/output_transform/kernel/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_1/self_attention/multihead_attention/output_transform/Tensordot/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_1/encdec_attention/layer_prepostprocess/layer_norm/layer_norm_scale/Read/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_1/encdec_attention/layer_prepostprocess/layer_norm/layer_norm_bias/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_1/encdec_attention/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_1/encdec_attention/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer/body/decoder/layer_1/encdec_attention/multihead_attention/q/kernel/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_1/encdec_attention/multihead_attention/q/Tensordot/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_1/encdec_attention/multihead_attention/k/kernel/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_1/encdec_attention/multihead_attention/k/Tensordot/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_1/encdec_attention/multihead_attention/v/kernel/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_1/encdec_attention/multihead_attention/v/Tensordot/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_1/encdec_attention/multihead_attention/output_transform/kernel/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_1/encdec_attention/multihead_attention/output_transform/Tensordot/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_1/ffn/layer_prepostprocess/layer_norm/layer_norm_scale/Read/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_1/ffn/layer_prepostprocess/layer_norm/layer_norm_bias/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_1_1/ffn/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_1_1/ffn/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer/body/decoder/layer_1/ffn/conv1/kernel/Read/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_1/ffn/conv1/bias/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_1_1/ffn/conv1/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_1_1/ffn/conv1/BiasAdd/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_1/ffn/conv2/kernel/Read/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_1/ffn/conv2/bias/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_1_1/ffn/conv2/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_1_1/ffn/conv2/BiasAdd/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_prepostprocess/layer_norm/layer_norm_scale/Read/ReadVariableOp',\n",
       " 'transformer/body/decoder/layer_prepostprocess/layer_norm/layer_norm_bias/Read/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer/parallel_0_4/transformer/transformer/body/decoder/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer_1/body/parallel_0/body/target_space_embedding/ReadVariableOp',\n",
       " 'transformer_1/body/parallel_0/body/encoder/layer_0/self_attention/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer_1/body/parallel_0/body/encoder/layer_0/self_attention/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer_1/body/parallel_0/body/encoder/layer_0/self_attention/multihead_attention/q/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/body/parallel_0/body/encoder/layer_0/self_attention/multihead_attention/k/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/body/parallel_0/body/encoder/layer_0/self_attention/multihead_attention/v/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/body/parallel_0/body/encoder/layer_0/self_attention/multihead_attention/output_transform/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/body/parallel_0/body/encoder/layer_0/ffn/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer_1/body/parallel_0/body/encoder/layer_0/ffn/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer_1/body/parallel_0/body/encoder/layer_0/ffn/conv1/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/body/parallel_0/body/encoder/layer_0/ffn/conv1/BiasAdd/ReadVariableOp',\n",
       " 'transformer_1/body/parallel_0/body/encoder/layer_0/ffn/conv2/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/body/parallel_0/body/encoder/layer_0/ffn/conv2/BiasAdd/ReadVariableOp',\n",
       " 'transformer_1/body/parallel_0/body/encoder/layer_1/self_attention/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer_1/body/parallel_0/body/encoder/layer_1/self_attention/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer_1/body/parallel_0/body/encoder/layer_1/self_attention/multihead_attention/q/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/body/parallel_0/body/encoder/layer_1/self_attention/multihead_attention/k/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/body/parallel_0/body/encoder/layer_1/self_attention/multihead_attention/v/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/body/parallel_0/body/encoder/layer_1/self_attention/multihead_attention/output_transform/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/body/parallel_0/body/encoder/layer_1/ffn/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer_1/body/parallel_0/body/encoder/layer_1/ffn/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer_1/body/parallel_0/body/encoder/layer_1/ffn/conv1/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/body/parallel_0/body/encoder/layer_1/ffn/conv1/BiasAdd/ReadVariableOp',\n",
       " 'transformer_1/body/parallel_0/body/encoder/layer_1/ffn/conv2/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/body/parallel_0/body/encoder/layer_1/ffn/conv2/BiasAdd/ReadVariableOp',\n",
       " 'transformer_1/body/parallel_0/body/encoder/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer_1/body/parallel_0/body/encoder/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer_1/body/decoder/layer_0/encdec_attention/multihead_attention/k/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/body/decoder/layer_0/encdec_attention/multihead_attention/v/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/body/decoder/layer_1/encdec_attention/multihead_attention/k/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/body/decoder/layer_1/encdec_attention/multihead_attention/v/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_0/self_attention/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_0/self_attention/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_0/self_attention/multihead_attention/q/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_0/self_attention/multihead_attention/k/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_0/self_attention/multihead_attention/v/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_0/self_attention/multihead_attention/output_transform/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_0/encdec_attention/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_0/encdec_attention/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_0/encdec_attention/multihead_attention/q/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_0/encdec_attention/multihead_attention/output_transform/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_0_1/ffn/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_0_1/ffn/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_0_1/ffn/conv1/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_0_1/ffn/conv1/BiasAdd/ReadVariableOp',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_0_1/ffn/conv2/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_0_1/ffn/conv2/BiasAdd/ReadVariableOp',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_1/self_attention/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_1/self_attention/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_1/self_attention/multihead_attention/q/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_1/self_attention/multihead_attention/k/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_1/self_attention/multihead_attention/v/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_1/self_attention/multihead_attention/output_transform/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_1/encdec_attention/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_1/encdec_attention/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_1/encdec_attention/multihead_attention/q/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_1/encdec_attention/multihead_attention/output_transform/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_1_1/ffn/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_1_1/ffn/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_1_1/ffn/conv1/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_1_1/ffn/conv1/BiasAdd/ReadVariableOp',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_1_1/ffn/conv2/Tensordot/ReadVariableOp',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_1_1/ffn/conv2/BiasAdd/ReadVariableOp',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer_1/while/body/parallel_0/body/decoder/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/target_space_embedding/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/encoder/layer_0/self_attention/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/encoder/layer_0/self_attention/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/encoder/layer_0/self_attention/multihead_attention/q/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/encoder/layer_0/self_attention/multihead_attention/k/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/encoder/layer_0/self_attention/multihead_attention/v/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/encoder/layer_0/self_attention/multihead_attention/output_transform/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/encoder/layer_0/ffn/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/encoder/layer_0/ffn/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/encoder/layer_0/ffn/conv1/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/encoder/layer_0/ffn/conv1/BiasAdd/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/encoder/layer_0/ffn/conv2/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/encoder/layer_0/ffn/conv2/BiasAdd/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/encoder/layer_1/self_attention/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/encoder/layer_1/self_attention/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/encoder/layer_1/self_attention/multihead_attention/q/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/encoder/layer_1/self_attention/multihead_attention/k/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/encoder/layer_1/self_attention/multihead_attention/v/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/encoder/layer_1/self_attention/multihead_attention/output_transform/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/encoder/layer_1/ffn/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/encoder/layer_1/ffn/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/encoder/layer_1/ffn/conv1/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/encoder/layer_1/ffn/conv1/BiasAdd/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/encoder/layer_1/ffn/conv2/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/encoder/layer_1/ffn/conv2/BiasAdd/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/encoder/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/encoder/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_0/self_attention/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_0/self_attention/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_0/self_attention/multihead_attention/q/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_0/self_attention/multihead_attention/k/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_0/self_attention/multihead_attention/v/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_0/self_attention/multihead_attention/output_transform/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_0/encdec_attention/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_0/encdec_attention/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_0/encdec_attention/multihead_attention/q/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_0/encdec_attention/multihead_attention/k/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_0/encdec_attention/multihead_attention/v/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_0/encdec_attention/multihead_attention/output_transform/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_0_1/ffn/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_0_1/ffn/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_0_1/ffn/conv1/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_0_1/ffn/conv1/BiasAdd/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_0_1/ffn/conv2/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_0_1/ffn/conv2/BiasAdd/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_1/self_attention/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_1/self_attention/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_1/self_attention/multihead_attention/q/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_1/self_attention/multihead_attention/k/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_1/self_attention/multihead_attention/v/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_1/self_attention/multihead_attention/output_transform/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_1/encdec_attention/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_1/encdec_attention/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_1/encdec_attention/multihead_attention/q/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_1/encdec_attention/multihead_attention/k/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_1/encdec_attention/multihead_attention/v/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_1/encdec_attention/multihead_attention/output_transform/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_1_1/ffn/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_1_1/ffn/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_1_1/ffn/conv1/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_1_1/ffn/conv1/BiasAdd/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_1_1/ffn/conv2/Tensordot/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_1_1/ffn/conv2/BiasAdd/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_prepostprocess/layer_norm/ReadVariableOp',\n",
       " 'transformer/parallel_0_10/transformer/transformer/body/decoder/layer_prepostprocess/layer_norm/ReadVariableOp_1',\n",
       " 'greedy',\n",
       " 'beam']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strings = ','.join(\n",
    "    [\n",
    "        n.name\n",
    "        for n in tf.get_default_graph().as_graph_def().node\n",
    "        if ('Variable' in n.op\n",
    "        or 'Placeholder' in n.name\n",
    "        or 'greedy' in n.name\n",
    "        or 'beam' in n.name\n",
    "        or 'alphas' in n.name\n",
    "        or 'temperature' in n.name\n",
    "        or 'beam_size' in n.name\n",
    "        or 'self/Softmax' in n.name)\n",
    "        and 'adam' not in n.name\n",
    "        and 'beta' not in n.name\n",
    "        and 'global_step' not in n.name\n",
    "        and 'modality' not in n.name\n",
    "        and 'Assign' not in n.name\n",
    "    ]\n",
    ")\n",
    "strings.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cbba97ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_graph(model_dir, output_node_names):\n",
    "\n",
    "    if not tf.gfile.Exists(model_dir):\n",
    "        raise AssertionError(\n",
    "            \"Export directory doesn't exists. Please specify an export \"\n",
    "            'directory: %s' % model_dir\n",
    "        )\n",
    "\n",
    "    checkpoint = tf.train.get_checkpoint_state(model_dir)\n",
    "    input_checkpoint = checkpoint.model_checkpoint_path\n",
    "\n",
    "    absolute_model_dir = '/'.join(input_checkpoint.split('/')[:-1])\n",
    "    output_graph = absolute_model_dir + '/frozen_model.pb'\n",
    "    clear_devices = True\n",
    "    with tf.Session(graph = tf.Graph()) as sess:\n",
    "        saver = tf.train.import_meta_graph(\n",
    "            input_checkpoint + '.meta', clear_devices = clear_devices\n",
    "        )\n",
    "        saver.restore(sess, input_checkpoint)\n",
    "        output_graph_def = tf.graph_util.convert_variables_to_constants(\n",
    "            sess,\n",
    "            tf.get_default_graph().as_graph_def(),\n",
    "            output_node_names.split(','),\n",
    "        )\n",
    "        with tf.gfile.GFile(output_graph, 'wb') as f:\n",
    "            f.write(output_graph_def.SerializeToString())\n",
    "        print('%d ops in the final graph.' % len(output_graph_def.node))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fe5a04e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_86718/3042836824.py:3: The name tf.gfile.Exists is deprecated. Please use tf.io.gfile.exists instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_86718/3042836824.py:3: The name tf.gfile.Exists is deprecated. Please use tf.io.gfile.exists instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_86718/3042836824.py:15: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_86718/3042836824.py:15: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_86718/3042836824.py:16: The name tf.train.import_meta_graph is deprecated. Please use tf.compat.v1.train.import_meta_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-02 15:28:50.978444: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1082] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-02 15:28:50.979144: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1666] Found device 0 with properties: \n",
      "name: NVIDIA GeForce RTX 3090 Ti major: 8 minor: 6 memoryClockRate(GHz): 1.86\n",
      "pciBusID: 0000:01:00.0\n",
      "2022-08-02 15:28:50.979165: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-08-02 15:28:50.979185: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2022-08-02 15:28:50.979193: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-08-02 15:28:50.979200: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-08-02 15:28:50.979206: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.11\n",
      "2022-08-02 15:28:50.979213: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2022-08-02 15:28:50.979219: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2022-08-02 15:28:50.979254: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1082] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-02 15:28:50.979905: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1082] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-02 15:28:50.980527: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1794] Adding visible gpu devices: 0\n",
      "2022-08-02 15:28:50.981217: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1082] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-02 15:28:50.981888: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1666] Found device 0 with properties: \n",
      "name: NVIDIA GeForce RTX 3090 Ti major: 8 minor: 6 memoryClockRate(GHz): 1.86\n",
      "pciBusID: 0000:01:00.0\n",
      "2022-08-02 15:28:50.981900: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-08-02 15:28:50.981910: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2022-08-02 15:28:50.981916: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-08-02 15:28:50.981921: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-08-02 15:28:50.981926: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.11\n",
      "2022-08-02 15:28:50.981931: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2022-08-02 15:28:50.981937: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2022-08-02 15:28:50.981974: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1082] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-02 15:28:50.982633: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1082] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-02 15:28:50.983635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1794] Adding visible gpu devices: 0\n",
      "2022-08-02 15:28:50.983663: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1206] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-08-02 15:28:50.983670: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1212]      0 \n",
      "2022-08-02 15:28:50.983676: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1225] 0:   N \n",
      "2022-08-02 15:28:50.983762: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1082] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-02 15:28:50.984433: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1082] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-02 15:28:50.985056: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1351] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 20283 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 3090 Ti, pci bus id: 0000:01:00.0, compute capability: 8.6)\n",
      "WARNING:tensorflow:From /tmp/ipykernel_86718/3042836824.py:16: The name tf.train.import_meta_graph is deprecated. Please use tf.compat.v1.train.import_meta_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from rumi-jawi-small/model.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from rumi-jawi-small/model.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 81 variables.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Froze 81 variables.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Converted 81 variables to const ops.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Converted 81 variables to const ops.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_86718/3042836824.py:25: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_86718/3042836824.py:25: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4441 ops in the final graph.\n"
     ]
    }
   ],
   "source": [
    "freeze_graph('rumi-jawi-small', strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5aa439da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_graph(frozen_graph_filename):\n",
    "    with tf.gfile.GFile(frozen_graph_filename, 'rb') as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "    with tf.Graph().as_default() as graph:\n",
    "        tf.import_graph_def(graph_def)\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7c45c9b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_86718/2300956737.py:3: The name tf.GraphDef is deprecated. Please use tf.compat.v1.GraphDef instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_86718/2300956737.py:3: The name tf.GraphDef is deprecated. Please use tf.compat.v1.GraphDef instead.\n",
      "\n",
      "2022-08-02 15:29:01.286624: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1082] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-02 15:29:01.287317: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1666] Found device 0 with properties: \n",
      "name: NVIDIA GeForce RTX 3090 Ti major: 8 minor: 6 memoryClockRate(GHz): 1.86\n",
      "pciBusID: 0000:01:00.0\n",
      "2022-08-02 15:29:01.287352: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-08-02 15:29:01.287372: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.11\n",
      "2022-08-02 15:29:01.287380: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-08-02 15:29:01.287387: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-08-02 15:29:01.287393: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.11\n",
      "2022-08-02 15:29:01.287400: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.11\n",
      "2022-08-02 15:29:01.287406: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.8\n",
      "2022-08-02 15:29:01.287468: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1082] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-02 15:29:01.288130: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1082] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-02 15:29:01.288745: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1794] Adding visible gpu devices: 0\n",
      "2022-08-02 15:29:01.288760: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1206] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-08-02 15:29:01.288764: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1212]      0 \n",
      "2022-08-02 15:29:01.288766: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1225] 0:   N \n",
      "2022-08-02 15:29:01.288820: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1082] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-02 15:29:01.289477: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1082] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-08-02 15:29:01.290104: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1351] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 20283 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 3090 Ti, pci bus id: 0000:01:00.0, compute capability: 8.6)\n",
      "/home/ubuntu/tf-nvidia/lib/python3.8/site-packages/tensorflow_core/python/client/session.py:1750: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    }
   ],
   "source": [
    "g = load_graph('rumi-jawi-small/frozen_model.pb')\n",
    "x = g.get_tensor_by_name('import/Placeholder:0')\n",
    "greedy = g.get_tensor_by_name('import/greedy:0')\n",
    "beam = g.get_tensor_by_name('import/beam:0')\n",
    "test_sess = tf.InteractiveSession(graph = g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6474da59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.tools.graph_transforms import TransformGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dc398b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rumi-jawi-small/frozen_model.pb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-02 15:29:11.126755: I tensorflow/tools/graph_transforms/transform_graph.cc:318] Applying add_default_attributes\n",
      "2022-08-02 15:29:11.146600: I tensorflow/tools/graph_transforms/transform_graph.cc:318] Applying remove_nodes\n",
      "2022-08-02 15:29:11.165985: I tensorflow/tools/graph_transforms/remove_nodes.cc:78] Skipping replacement for greedy\n",
      "2022-08-02 15:29:11.166023: I tensorflow/tools/graph_transforms/remove_nodes.cc:78] Skipping replacement for beam\n",
      "2022-08-02 15:29:11.190569: I tensorflow/tools/graph_transforms/remove_nodes.cc:78] Skipping replacement for greedy\n",
      "2022-08-02 15:29:11.190607: I tensorflow/tools/graph_transforms/remove_nodes.cc:78] Skipping replacement for beam\n",
      "2022-08-02 15:29:11.212373: I tensorflow/tools/graph_transforms/remove_nodes.cc:78] Skipping replacement for greedy\n",
      "2022-08-02 15:29:11.212409: I tensorflow/tools/graph_transforms/remove_nodes.cc:78] Skipping replacement for beam\n",
      "2022-08-02 15:29:11.233585: I tensorflow/tools/graph_transforms/remove_nodes.cc:78] Skipping replacement for greedy\n",
      "2022-08-02 15:29:11.233620: I tensorflow/tools/graph_transforms/remove_nodes.cc:78] Skipping replacement for beam\n",
      "2022-08-02 15:29:11.296925: I tensorflow/tools/graph_transforms/transform_graph.cc:318] Applying fold_constants\n",
      "2022-08-02 15:29:11.489478: I tensorflow/tools/graph_transforms/transform_graph.cc:318] Applying fold_batch_norms\n",
      "2022-08-02 15:29:11.514828: I tensorflow/tools/graph_transforms/transform_graph.cc:318] Applying fold_old_batch_norms\n",
      "2022-08-02 15:29:11.582983: I tensorflow/tools/graph_transforms/transform_graph.cc:318] Applying quantize_weights\n",
      "2022-08-02 15:29:11.749053: I tensorflow/tools/graph_transforms/transform_graph.cc:318] Applying strip_unused_nodes\n",
      "2022-08-02 15:29:11.768310: I tensorflow/tools/graph_transforms/transform_graph.cc:318] Applying sort_by_execution_order\n"
     ]
    }
   ],
   "source": [
    "transforms = ['add_default_attributes',\n",
    "             'remove_nodes(op=Identity, op=CheckNumerics, op=Dropout)',\n",
    "             'fold_constants(ignore_errors=true)',\n",
    "             'fold_batch_norms',\n",
    "             'fold_old_batch_norms',\n",
    "             'quantize_weights(fallback_min=-10, fallback_max=10)',\n",
    "             'strip_unused_nodes',\n",
    "             'sort_by_execution_order']\n",
    "\n",
    "pb = 'rumi-jawi-small/frozen_model.pb'\n",
    "input_graph_def = tf.GraphDef()\n",
    "with tf.gfile.FastGFile(pb, 'rb') as f:\n",
    "    input_graph_def.ParseFromString(f.read())\n",
    "\n",
    "print(pb)\n",
    "\n",
    "transformed_graph_def = TransformGraph(input_graph_def, \n",
    "                                       ['Placeholder', 'beam_size', 'temperature'],\n",
    "                                       ['greedy', 'beam'], transforms)\n",
    "\n",
    "with tf.gfile.GFile(f'{pb}.quantized', 'wb') as f:\n",
    "    f.write(transformed_graph_def.SerializeToString())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a4928673",
   "metadata": {},
   "outputs": [],
   "source": [
    "from malaya_boilerplate.huggingface import upload_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "85ca2c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rumi-jawi-small/\n",
      "rumi-jawi-small/checkpoint\n",
      "rumi-jawi-small/frozen_model.pb.quantized\n",
      "rumi-jawi-small/events.out.tfevents.1659413245.huseincomel-desktop\n",
      "rumi-jawi-small/events.out.tfevents.1659413066.huseincomel-desktop\n",
      "rumi-jawi-small/model.ckpt.index\n",
      "rumi-jawi-small/model.ckpt.data-00000-of-00001\n",
      "rumi-jawi-small/model.ckpt.meta\n",
      "rumi-jawi-small/frozen_model.pb\n"
     ]
    }
   ],
   "source": [
    "!cp t2t-rumi-jawi/small/*.tfevents.* rumi-jawi-small\n",
    "!tar -cvf rumi-jawi-small.tar rumi-jawi-small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0d66c03a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/tf-nvidia/lib/python3.8/site-packages/huggingface_hub/hf_api.py:79: FutureWarning: `name` and `organization` input arguments are deprecated and will be removed in v0.8. Pass `repo_id` instead.\n",
      "  warnings.warn(\n",
      "WARNING:malaya_boilerplate.huggingface:409 Client Error: Conflict for url: https://huggingface.co/api/repos/create - You already created this model repo\n"
     ]
    }
   ],
   "source": [
    "files_mapping = {'rumi-jawi-small.tar': 'rumi-jawi-small.tar'}\n",
    "upload_dict(model = 'pretrained-rumi-jawi', files_mapping = files_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "310d22ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_mapping = {'rumi-jawi-small/frozen_model.pb': 'model.pb'}\n",
    "upload_dict(model = 'rumi-jawi-small', files_mapping = files_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "01f4b994",
   "metadata": {},
   "outputs": [],
   "source": [
    "files_mapping = {'rumi-jawi-small/frozen_model.pb.quantized': 'model.pb'}\n",
    "upload_dict(model = 'rumi-jawi-small-quantized', files_mapping = files_mapping)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf1",
   "language": "python",
   "name": "tf1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
